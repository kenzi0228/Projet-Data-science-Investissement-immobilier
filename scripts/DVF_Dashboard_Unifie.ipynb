{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd85216f",
   "metadata": {},
   "source": [
    "# Projet Immobilier — Notebook Unifié\n",
    "\n",
    "Ce notebook centralise **préparation des données**, **widgets d’exploration**, **analyse des loyers en IDF**, et **accessibilité aux gares IDF** dans **une seule interface**.\n",
    "\n",
    "> Conseil : exécutez les cellules dans l’ordre. La première section ci‑dessous fournit une *UI unifiée* pour piloter toutes les vues. Les sections originales des 4 notebooks sont conservées plus bas, telles quelles, pour assurer la compatibilité et faciliter le debug.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede47592",
   "metadata": {},
   "source": [
    "### Dépendances\n",
    "Assurez‑vous d'avoir ces bibliothèques installées dans l'environnement du notebook :\n",
    "- `pandas`, `numpy`\n",
    "- `ipywidgets` (et activer l'extension Jupyter classique au besoin), `IPython.display`\n",
    "- `matplotlib`, `plotly` (si utilisé par vos notebooks d'origine)\n",
    "- `pyarrow` (si vous lisez/écrivez des Parquet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2fcb430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7368b55f1cc2456b954f1a73115326da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h3>Filtres</h3>'), IntRangeSlider(value=(2025, 2025), continuous_up…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================== APP NOTEBOOK UNIFIÉE (COLLER/EXÉCUTER) ====================\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, ipywidgets as W\n",
    "from IPython.display import display, clear_output\n",
    "from pathlib import Path\n",
    "\n",
    "# -------- 1) CHARGEMENT DATA (adapte si tu as déjà un df propre) --------\n",
    "def _find_raw():\n",
    "    for d in [Path(\"./data\"), Path(\"../data\"), Path(\"/mnt/data\"), Path(\".\")]:\n",
    "        if d.exists():\n",
    "            for p in d.rglob(\"*\"):\n",
    "                n = p.name.lower()\n",
    "                if p.is_file() and ((\"dvf\" in n or \"valeurs_foncieres\" in n) and p.suffix.lower() in [\".csv\",\".txt\"]):\n",
    "                    return p\n",
    "    return None\n",
    "\n",
    "def _guess_sep(fp: Path):\n",
    "    with open(fp, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        h=f.readline()\n",
    "    return \";\" if h.count(\";\")>=h.count(\",\") else \",\"\n",
    "\n",
    "def load_data():\n",
    "    # Priorité à un parquet déjà prêt\n",
    "    clean = Path(\"./data_clean/dvf_clean.parquet\")\n",
    "    if clean.exists():\n",
    "        return pd.read_parquet(clean)\n",
    "    alt = Path(\"/mnt/data/dvf_clean.parquet\")\n",
    "    if alt.exists():\n",
    "        return pd.read_parquet(alt)\n",
    "\n",
    "    raw = _find_raw()\n",
    "    if raw is None:\n",
    "        return pd.DataFrame()\n",
    "    sep = _guess_sep(raw)\n",
    "    dtype_hint = {\n",
    "        \"valeur_fonciere\":\"float64\",\"surface_reelle_bati\":\"float64\",\"nombre_pieces_principales\":\"float64\",\n",
    "        \"code_postal\":\"string\",\"code_commune\":\"string\",\"nom_commune\":\"string\",\"type_local\":\"string\",\"annee\":\"Int64\"\n",
    "    }\n",
    "    df = pd.read_csv(raw, sep=sep, dtype=dtype_hint, low_memory=False, encoding=\"utf-8\", na_values=[\"\",\"NA\",\"NaN\"])\n",
    "    if \"valeur_fonciere\" in df and \"surface_reelle_bati\" in df:\n",
    "        vf = pd.to_numeric(df[\"valeur_fonciere\"], errors=\"coerce\")\n",
    "        sr = pd.to_numeric(df[\"surface_reelle_bati\"], errors=\"coerce\")\n",
    "        df[\"prix_m2\"] = vf/sr\n",
    "    return df\n",
    "\n",
    "STATE = {\"df\": load_data(), \"df_f\": None}\n",
    "\n",
    "# -------- 2) FILTRES GLOBAUX --------\n",
    "df0 = STATE[\"df\"]\n",
    "years = sorted([int(x) for x in df0[\"annee\"].dropna().unique().tolist()]) if \"annee\" in df0.columns else []\n",
    "yr_min, yr_max = (years[0], years[-1]) if years else (2000, 2025)\n",
    "\n",
    "flt_year    = W.IntRangeSlider(description=\"Années\", min=yr_min, max=yr_max, value=(yr_min, yr_max), step=1, continuous_update=False, layout=W.Layout(width=\"360px\"))\n",
    "flt_type    = W.SelectMultiple(options=sorted(df0[\"type_local\"].dropna().unique().tolist()) if \"type_local\" in df0.columns else [], description=\"Type\", rows=4, layout=W.Layout(width=\"360px\"))\n",
    "flt_commune = W.Combobox(options=sorted(df0[\"nom_commune\"].dropna().unique().tolist())[:500] if \"nom_commune\" in df0.columns else [], placeholder=\"Commune (optionnel)\", layout=W.Layout(width=\"360px\"))\n",
    "btn_apply   = W.Button(description=\"Appliquer\")\n",
    "btn_reset   = W.Button(description=\"Réinit\")\n",
    "\n",
    "# -------- 3) PANNEAUX D’AFFICHAGE --------\n",
    "out_data = W.Output(); out_w56 = W.Output(); out_loyers = W.Output(); out_gares = W.Output()\n",
    "\n",
    "# ====== REMPLACE UNIQUEMENT LE CONTENU DE CES 3 FONCTIONS AVEC TES VISU ======\n",
    "def panel_widgets_5_6(df: pd.DataFrame, out: W.Output):\n",
    "    \"\"\"Colle ici ton code des widgets 5 & 6.\"\"\"\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if df is None or df.empty:\n",
    "            print(\"Aucune donnée filtrée.\")\n",
    "            return\n",
    "        if {\"valeur_fonciere\",\"surface_reelle_bati\"} <= set(df.columns):\n",
    "            plt.figure()\n",
    "            sam = df[[\"valeur_fonciere\",\"surface_reelle_bati\"]].dropna().sample(min(3000, len(df)), random_state=42)\n",
    "            plt.scatter(sam[\"surface_reelle_bati\"], sam[\"valeur_fonciere\"], s=6)\n",
    "            plt.title(\"Valeur foncière vs Surface (échantillon)\")\n",
    "            plt.xlabel(\"Surface (m²)\"); plt.ylabel(\"Valeur (€)\")\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Ajoute ici tes graphes existants (colonnes manquantes pour l’exemple).\")\n",
    "\n",
    "def panel_loyers_idf(df: pd.DataFrame, out: W.Output):\n",
    "    \"\"\"Colle ici ton code ‘analyse loyers IDF’.\"\"\"\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if df is None or df.empty:\n",
    "            print(\"Aucune donnée filtrée.\")\n",
    "            return\n",
    "        if \"code_postal\" in df.columns and \"prix_m2\" in df.columns:\n",
    "            t = df.copy()\n",
    "            t[\"dept\"] = t[\"code_postal\"].astype(str).str[:2]\n",
    "            idf = {\"75\",\"77\",\"78\",\"91\",\"92\",\"93\",\"94\",\"95\"}\n",
    "            t = t[t[\"dept\"].isin(idf)]\n",
    "            if t.empty:\n",
    "                print(\"Pas de lignes IDF après filtres.\")\n",
    "                return\n",
    "            g = t.groupby(\"dept\")[\"prix_m2\"].median().sort_index()\n",
    "            display(g.to_frame(\"prix_m2_median\"))\n",
    "            plt.figure(); g.plot(kind=\"bar\"); plt.title(\"Prix/m² médian (IDF)\"); plt.xlabel(\"Département\"); plt.ylabel(\"€/m²\"); plt.show()\n",
    "        else:\n",
    "            print(\"Ajoute ici ton analyse loyers (code_postal / prix_m2 requis pour l’exemple).\")\n",
    "\n",
    "def panel_access_gares(df: pd.DataFrame, out: W.Output):\n",
    "    \"\"\"Colle ici ton code ‘accessibilité gares IDF’ (jointure sur table gares).\"\"\"\n",
    "    with out:\n",
    "        clear_output()\n",
    "        print(\"Place ici ta jointure DF <-> Gares + tes visus (carte, histogrammes, etc.).\")\n",
    "# ==============================================================================\n",
    "\n",
    "# -------- 4) PANEL DONNÉES & KPI (garde si utile) --------\n",
    "def panel_data(df: pd.DataFrame, out: W.Output):\n",
    "    with out:\n",
    "        clear_output()\n",
    "        if df is None or df.empty:\n",
    "            print(\"Aucune donnée filtrée.\")\n",
    "            return\n",
    "        n = len(df); cols = len(df.columns)\n",
    "        print(f\"Lignes: {n:,} | Colonnes: {cols}\")\n",
    "        if \"prix_m2\" in df:  print(\"Médiane prix/m²:\", f\"{np.nanmedian(df['prix_m2']):,.0f}\")\n",
    "        if \"surface_reelle_bati\" in df: print(\"Médiane surface:\", f\"{np.nanmedian(df['surface_reelle_bati']):,.1f} m²\")\n",
    "        display(df.head(10))\n",
    "        if \"prix_m2\" in df:\n",
    "            plt.figure()\n",
    "            df[\"prix_m2\"].dropna().clip(upper=df[\"prix_m2\"].quantile(0.99)).hist(bins=40)\n",
    "            plt.title(\"Distribution prix/m²\"); plt.xlabel(\"€/m²\"); plt.ylabel(\"Fréquence\"); plt.show()\n",
    "\n",
    "# -------- 5) FILTRAGE GLOBAL + REFRESH --------\n",
    "def _apply(_=None):\n",
    "    df = STATE[\"df\"]\n",
    "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
    "        STATE[\"df_f\"] = None\n",
    "    else:\n",
    "        m = pd.Series(True, index=df.index)\n",
    "        if \"annee\" in df:\n",
    "            y0, y1 = flt_year.value\n",
    "            m &= df[\"annee\"].fillna(-1).astype(\"Int64\").between(y0, y1)\n",
    "        if flt_type.value and \"type_local\" in df:\n",
    "            m &= df[\"type_local\"].isin(list(flt_type.value))\n",
    "        if flt_commune.value and \"nom_commune\" in df:\n",
    "            m &= df[\"nom_commune\"].fillna(\"\").str.lower().eq(str(flt_commune.value).strip().lower())\n",
    "        STATE[\"df_f\"] = df[m].copy()\n",
    "\n",
    "    panel_data(STATE[\"df_f\"], out_data)\n",
    "    panel_widgets_5_6(STATE[\"df_f\"], out_w56)\n",
    "    panel_loyers_idf(STATE[\"df_f\"], out_loyers)\n",
    "    panel_access_gares(STATE[\"df_f\"], out_gares)\n",
    "\n",
    "def _reset(_=None):\n",
    "    if \"annee\" in STATE[\"df\"].columns:\n",
    "        ys = sorted([int(x) for x in STATE[\"df\"][\"annee\"].dropna().unique().tolist()])\n",
    "        if ys:\n",
    "            flt_year.min, flt_year.max = ys[0], ys[-1]\n",
    "            flt_year.value = (ys[0], ys[-1])\n",
    "    flt_type.value = tuple()\n",
    "    flt_commune.value = \"\"\n",
    "    _apply()\n",
    "\n",
    "btn_apply.on_click(_apply); btn_reset.on_click(_reset)\n",
    "\n",
    "# -------- 6) LAYOUT --------\n",
    "sidebar = W.VBox([W.HTML(\"<h3>Filtres</h3>\"), flt_year, flt_type, flt_commune, W.HBox([btn_apply, btn_reset])],\n",
    "                 layout=W.Layout(width=\"380px\"))\n",
    "tabs = W.Tab(children=[out_data, out_w56, out_loyers, out_gares])\n",
    "for i, t in enumerate([\"Données & KPI\", \"Widgets 5&6\", \"Loyers IDF\", \"Accès gares IDF\"]):\n",
    "    tabs.set_title(i, t)\n",
    "display(W.HBox([sidebar, tabs]))\n",
    "_apply()\n",
    "# ===============================================================================\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594a85b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Sections originales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdedf301",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Import automatique de `01_prepare_data.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b44f52",
   "metadata": {},
   "source": [
    "## Imports & chemins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "821b8cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375235559e374ebf81fc79a5d3bc7237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HTML(value='<h3>Paramètres d’analyse</h3>'), HBox(children=(IntRangeSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== Projet Immobilier — Chargement, Nettoyage, Codes Postaux (robuste) + Dashboard =====\n",
    "import os, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "RAW_DIR   = os.path.abspath(os.path.join(\"..\", \"data\", \"raw\"))\n",
    "CLEAN_DIR = os.path.abspath(os.path.join(\"..\", \"data\", \"clean\"))\n",
    "Path(CLEAN_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def to_num_fr(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str).str.replace(\"\\u00A0\",\"\", regex=False)\n",
    "    s = s.str.replace(\" \", \"\", regex=False).str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def parse_dates_robust(s: pd.Series) -> pd.Series:\n",
    "    x = (s.astype(str).str.replace(\"\\u00A0\",\" \", regex=False)\n",
    "                 .str.strip().str.replace(r\"[^0-9/\\-]\", \"\", regex=True))\n",
    "    out = pd.to_datetime(x, errors=\"coerce\", dayfirst=True)\n",
    "    mask = out.isna()\n",
    "    if mask.any():\n",
    "        out.loc[mask] = pd.to_datetime(x.loc[mask], errors=\"coerce\", format=\"%Y-%m-%d\")\n",
    "    return out\n",
    "\n",
    "def load_dvf_idf(dvf_path: str, out_fp: str) -> pd.DataFrame:\n",
    "    if os.path.exists(out_fp):\n",
    "        return pd.read_parquet(out_fp)\n",
    "\n",
    "    usecols = [\"Date mutation\",\"Nature mutation\",\"Valeur fonciere\",\n",
    "               \"Code postal\",\"Commune\",\"Code departement\",\"Code commune\",\n",
    "               \"Type local\",\"Surface reelle bati\",\"Nombre pieces principales\"]\n",
    "    idf = (\"75\",\"77\",\"78\",\"91\",\"92\",\"93\",\"94\",\"95\")\n",
    "\n",
    "    chunks, tried = [], []\n",
    "    for enc in (\"cp1252\",\"latin1\",\"utf-8\",\"utf-8-sig\"):\n",
    "        try:\n",
    "            for chunk in pd.read_csv(dvf_path, sep=\"|\", usecols=usecols,\n",
    "                                     encoding=enc, dtype=str, chunksize=200_000):\n",
    "                # Renommage\n",
    "                chunk = chunk.rename(columns={\n",
    "                    \"Date mutation\":\"date_mutation\",\n",
    "                    \"Valeur fonciere\":\"valeur_fonciere\",\n",
    "                    \"Surface reelle bati\":\"surface_reelle_bati\",\n",
    "                    \"Commune\":\"nom_commune\",\n",
    "                    \"Code postal\":\"code_postal\",\n",
    "                    \"Type local\":\"type_local\",\n",
    "                    \"Code departement\":\"code_departement\",\n",
    "                    \"Code commune\":\"code_commune_3\",\n",
    "                })\n",
    "\n",
    "                # Île-de-France\n",
    "                m_idf = chunk[\"code_departement\"].astype(str).str.strip().str[:2].isin(idf)\n",
    "                chunk = chunk[m_idf]\n",
    "\n",
    "                # Types et conversions\n",
    "                chunk[\"date_mutation\"]       = parse_dates_robust(chunk[\"date_mutation\"])\n",
    "                chunk[\"annee\"]               = chunk[\"date_mutation\"].dt.year\n",
    "                chunk[\"valeur_fonciere\"]     = to_num_fr(chunk[\"valeur_fonciere\"])\n",
    "                chunk[\"surface_reelle_bati\"] = to_num_fr(chunk[\"surface_reelle_bati\"])\n",
    "\n",
    "                # Codes & prix/m²\n",
    "                chunk[\"code_departement\"]     = chunk[\"code_departement\"].astype(str).str.strip().str.zfill(2)\n",
    "                chunk[\"code_commune_3\"]       = chunk[\"code_commune_3\"].astype(str).str.strip().str.zfill(3)\n",
    "                chunk[\"code_commune_insee\"]   = chunk[\"code_departement\"] + chunk[\"code_commune_3\"]\n",
    "                chunk[\"prix_m2\"]              = chunk[\"valeur_fonciere\"] / chunk[\"surface_reelle_bati\"]\n",
    "\n",
    "                # Sélection minimale\n",
    "                keep = chunk[[\n",
    "                    \"date_mutation\",\"annee\",\"valeur_fonciere\",\"surface_reelle_bati\",\"prix_m2\",\n",
    "                    \"nom_commune\",\"code_commune_insee\",\"code_postal\"\n",
    "                ]]\n",
    "\n",
    "                chunks.append(keep)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            tried.append((enc, str(e)))\n",
    "            continue\n",
    "\n",
    "    if not chunks:\n",
    "        raise RuntimeError(f\"Lecture DVF vide. Encodings testés: {tried}\")\n",
    "\n",
    "    df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "    # Filtres de cohérence\n",
    "    df = df.dropna(subset=[\"date_mutation\",\"annee\",\"valeur_fonciere\",\"surface_reelle_bati\",\"prix_m2\",\"nom_commune\"])\n",
    "    df = df[(df[\"surface_reelle_bati\"] > 8) & (df[\"valeur_fonciere\"] > 1000) & (df[\"prix_m2\"].between(100, 30000))]\n",
    "    df.to_parquet(out_fp, index=False)\n",
    "    return df\n",
    "\n",
    "# --- Chargement DVF ---\n",
    "dvf_path = os.path.join(RAW_DIR, \"DVF_2025_S1.txt\")\n",
    "clean_fp = os.path.join(CLEAN_DIR, \"dvf_clean.parquet\")\n",
    "dvf = load_dvf_idf(dvf_path, clean_fp)\n",
    "\n",
    "# --- Jointure Codes Postaux (hyper-robuste encodage + noms/structures variés) ---\n",
    "import re\n",
    "\n",
    "codes_csv = os.path.join(RAW_DIR, \"Base_codes_postaux.csv\")\n",
    "\n",
    "def _norm_colname(c: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"_\", c.lower()).strip(\"_\")\n",
    "\n",
    "def read_codes_postaux(path: str) -> pd.DataFrame:\n",
    "    # 1) Lecture robuste (encodage + séparateur auto)\n",
    "    encodings = [\"cp1252\", \"latin1\", \"utf-8\", \"utf-8-sig\"]\n",
    "    last_err = None\n",
    "    for enc in encodings:\n",
    "        try:\n",
    "            dfc = pd.read_csv(path, sep=None, engine=\"python\", encoding=enc, dtype=str)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    else:\n",
    "        raise last_err\n",
    "\n",
    "    # 2) Normalisation des noms de colonnes\n",
    "    orig_cols = list(dfc.columns)\n",
    "    norm_cols = [_norm_colname(c) for c in dfc.columns]\n",
    "    dfc.columns = norm_cols\n",
    "\n",
    "    # 3) Alias possibles\n",
    "    insee_aliases   = {\n",
    "        \"code_commune_insee\",\"code_insee\",\"insee\",\"insee_code\",\n",
    "        \"codecommuneinsee\",\"codgeo\",\"code_commune_insee_2020\",\"code_commune_insee_2024\"\n",
    "    }\n",
    "    postal_aliases  = {\n",
    "        \"code_postal\",\"cp\",\"postal\",\"postal_code\",\"codepostal\",\"code_postal_commune\"\n",
    "    }\n",
    "    dept_aliases    = {\"code_departement\",\"departement\",\"dep\",\"code_dept\",\"dept\",\"code_dep\"}\n",
    "    com3_aliases    = {\"code_commune\",\"codecom\",\"codcom\",\"code_comm\",\"code_commune_3\"}\n",
    "\n",
    "    # 4) Détection colonnes\n",
    "    cols_set = set(dfc.columns)\n",
    "\n",
    "    def pick_any(candidates:set[str]) -> str|None:\n",
    "        for c in candidates:\n",
    "            if c in cols_set:\n",
    "                return c\n",
    "        return None\n",
    "\n",
    "    col_insee  = pick_any(insee_aliases)\n",
    "    col_cp     = pick_any(postal_aliases)\n",
    "    col_dept   = pick_any(dept_aliases)\n",
    "    col_com3   = pick_any(com3_aliases)\n",
    "\n",
    "    # 5) Si INSEE manquant, mais dept + com3 dispos -> construire\n",
    "    if col_insee is None and (col_dept is not None and col_com3 is not None):\n",
    "        # sécuriser formats\n",
    "        dfc[col_dept] = dfc[col_dept].astype(str).str.strip().str.zfill(2)\n",
    "        dfc[col_com3] = dfc[col_com3].astype(str).str.strip().str.zfill(3)\n",
    "        dfc[\"code_commune_insee\"] = dfc[col_dept] + dfc[col_com3]\n",
    "        col_insee = \"code_commune_insee\"\n",
    "\n",
    "    # 6) Si CP introuvable mais colonne nom proche \"code_postal\" existe avec typos courantes\n",
    "    if col_cp is None:\n",
    "        # Heuristique: chercher une colonne qui contient \"cp\" ou \"postal\"\n",
    "        candidates = [c for c in dfc.columns if (\"postal\" in c or c == \"cp\" or c.endswith(\"_cp\"))]\n",
    "        col_cp = candidates[0] if candidates else None\n",
    "\n",
    "    # 7) Validation\n",
    "    if col_insee is None or col_cp is None:\n",
    "        # Aide au debug: montrer colonnes disponibles\n",
    "        raise ValueError(\n",
    "            \"Le fichier codes postaux doit contenir INSEE et CP.\\n\"\n",
    "            f\"Colonnes disponibles (normalisées): {dfc.columns.tolist()}\\n\"\n",
    "            \"Essayé: INSEE in {insee_aliases} ou (dept in {dept_aliases} + com3 in {com3_aliases}); \"\n",
    "            f\"CP in {postal_aliases}.\"\n",
    "        )\n",
    "\n",
    "    # 8) Sélection + nettoyage minimal\n",
    "    out = dfc[[col_insee, col_cp]].rename(columns={col_insee: \"code_commune_insee\", col_cp: \"code_postal\"}).copy()\n",
    "    out[\"code_commune_insee\"] = out[\"code_commune_insee\"].astype(str).str.strip()\n",
    "    out[\"code_postal\"]        = out[\"code_postal\"].astype(str).str.strip()\n",
    "    out = out.dropna(subset=[\"code_commune_insee\",\"code_postal\"])\n",
    "    # garder CP à 5 chiffres si applicable\n",
    "    out[\"code_postal\"] = out[\"code_postal\"].str.extract(r\"(\\d{5})\", expand=False).fillna(out[\"code_postal\"])\n",
    "    return out\n",
    "\n",
    "codes = read_codes_postaux(codes_csv)\n",
    "\n",
    "# Choix d’un CP de référence par INSEE (mode sinon 1er)\n",
    "cp_ref = (codes.groupby(\"code_commune_insee\")[\"code_postal\"]\n",
    "               .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0])\n",
    "               .rename(\"code_postal_ref\")\n",
    "               .reset_index())\n",
    "\n",
    "# Merge sécurisé\n",
    "dvf = dvf.drop(columns=[\"code_postal\"], errors=\"ignore\").merge(cp_ref, on=\"code_commune_insee\", how=\"left\")\n",
    "dvf = dvf.rename(columns={\"code_postal_ref\":\"code_postal\"})\n",
    "dvf.to_parquet(clean_fp, index=False)\n",
    "\n",
    "\n",
    "# ================================== Dashboard interactif ==================================\n",
    "import ipywidgets as W\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "df = pd.read_parquet(clean_fp).copy()\n",
    "\n",
    "def iqr_bounds(s, k=2.0):\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    return q1 - k*iqr, q3 + k*iqr\n",
    "\n",
    "def apply_outliers(d, use_iqr=True):\n",
    "    if (not use_iqr) or (len(d) < 50):\n",
    "        return d\n",
    "    lo, hi = iqr_bounds(d[\"prix_m2\"], k=2.0)\n",
    "    return d[d[\"prix_m2\"].between(lo, hi)]\n",
    "\n",
    "def filter_by_surface(d, s_range):\n",
    "    smin, smax = s_range\n",
    "    return d[d[\"surface_reelle_bati\"].between(smin, smax)]\n",
    "\n",
    "def compute_yield(d, loyer_m2):\n",
    "    out = d.copy()\n",
    "    out[\"revenu_annuel\"] = loyer_m2 * out[\"surface_reelle_bati\"] * 12.0\n",
    "    out[\"yield_brut\"]    = out[\"revenu_annuel\"] / out[\"valeur_fonciere\"]\n",
    "    return out\n",
    "\n",
    "# Widgets\n",
    "w_surface = W.IntRangeSlider(value=(20, 80), min=10, max=200, step=1,\n",
    "                             description=\"Surface (m²)\", continuous_update=False)\n",
    "w_loyer   = W.FloatSlider(value=22.0, min=5.0, max=45.0, step=0.5,\n",
    "                          readout_format=\".1f\", description=\"Loyer €/m²\", continuous_update=False)\n",
    "w_topn    = W.IntSlider(value=15, min=5, max=50, step=1, description=\"Top N\", continuous_update=False)\n",
    "w_out     = W.Checkbox(value=True, description=\"Filtrer outliers (IQR)\")\n",
    "w_show_hist = W.Checkbox(value=True, description=\"Histogramme prix/m²\")\n",
    "\n",
    "out = W.Output()\n",
    "\n",
    "def render(_=None):\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        d = filter_by_surface(df, w_surface.value)\n",
    "        d = apply_outliers(d, w_out.value)\n",
    "        d = compute_yield(d, w_loyer.value)\n",
    "\n",
    "        nb     = len(d)\n",
    "        p50    = float(d[\"prix_m2\"].median()) if nb else np.nan\n",
    "        y_med  = float(d[\"yield_brut\"].median()) if nb else np.nan\n",
    "        html = f\"\"\"\n",
    "        <div>\n",
    "          <h3>KPIs</h3>\n",
    "          <ul>\n",
    "            <li>Transactions : {nb:,}</li>\n",
    "            <li>Prix/m² (médiane) : {p50:,.0f} €</li>\n",
    "            <li>Rendement brut (médiane) : {y_med*100:,.1f} %</li>\n",
    "          </ul>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "        display(W.HTML(html))\n",
    "\n",
    "        if nb:\n",
    "            # Top N communes par rendement médian\n",
    "            top = (d.groupby(\"nom_commune\", as_index=False)[\"yield_brut\"]\n",
    "                     .median().sort_values(\"yield_brut\", ascending=False).head(w_topn.value))\n",
    "            display(top)\n",
    "\n",
    "            # Scatter prix/m² vs surface\n",
    "            plt.figure(figsize=(6,4))\n",
    "            d.sample(min(2000, nb), random_state=0).plot(kind=\"scatter\", x=\"surface_reelle_bati\", y=\"prix_m2\")\n",
    "            plt.title(\"Prix/m² vs Surface (échantillon)\")\n",
    "            plt.xlabel(\"Surface (m²)\"); plt.ylabel(\"Prix/m² (€)\")\n",
    "            plt.show()\n",
    "\n",
    "            # Histogramme prix/m² (optionnel)\n",
    "            if w_show_hist.value:\n",
    "                plt.figure(figsize=(6,4))\n",
    "                d[\"prix_m2\"].dropna().clip(0, d[\"prix_m2\"].quantile(0.99)).plot(kind=\"hist\", bins=40)\n",
    "                plt.title(\"Distribution du prix/m² (troncature au 99e centile)\")\n",
    "                plt.xlabel(\"Prix/m² (€)\")\n",
    "                plt.ylabel(\"Fréquence\")\n",
    "                plt.show()\n",
    "\n",
    "controls = W.VBox([\n",
    "    W.HTML(\"<h3>Paramètres d’analyse</h3>\"),\n",
    "    W.HBox([w_surface, w_loyer]),\n",
    "    W.HBox([w_topn, w_out, w_show_hist])\n",
    "])\n",
    "\n",
    "ui = W.HBox([controls, out], layout=W.Layout(align_items=\"flex-start\"))\n",
    "display(ui)\n",
    "\n",
    "for w in (w_surface, w_loyer, w_topn, w_out, w_show_hist):\n",
    "    w.observe(render, \"value\")\n",
    "\n",
    "render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bc90f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ":root{\n",
       "  --bg:#0f172a;         /* slate-900 */\n",
       "  --panel:#111827;      /* gray-900 */\n",
       "  --card:#131a2a;       /* custom */\n",
       "  --muted:#9ca3af;      /* gray-400 */\n",
       "  --text:#e5e7eb;       /* gray-200 */\n",
       "  --accent:#22d3ee;     /* cyan-400 */\n",
       "  --accent2:#60a5fa;    /* blue-400 */\n",
       "}\n",
       "div.app-wrap{\n",
       "  background:linear-gradient(135deg,#0f172a 0%,#0b1220 100%);\n",
       "  color:var(--text);\n",
       "  padding:16px 16px 24px 16px; border-radius:16px;\n",
       "  box-shadow:0 10px 30px rgba(0,0,0,.35);\n",
       "  font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica Neue, Arial;\n",
       "}\n",
       ".app-title{\n",
       "  font-size:20px; font-weight:600; letter-spacing:.2px; margin:0 0 8px 0;\n",
       "}\n",
       ".app-subtitle{\n",
       "  color:var(--muted); font-size:13px; margin:0 0 14px 0;\n",
       "}\n",
       ".grid-2{\n",
       "  display:grid; grid-template-columns: 1.1fr 1fr; gap:16px; align-items:start;\n",
       "}\n",
       ".card{\n",
       "  background:var(--panel); border:1px solid rgba(255,255,255,.06);\n",
       "  border-radius:14px; padding:12px 12px;\n",
       "}\n",
       ".controls-grid{\n",
       "  display:grid; grid-template-columns:1fr 1fr; gap:10px;\n",
       "}\n",
       ".kpis{ display:grid; grid-template-columns: repeat(3, 1fr); gap:10px; }\n",
       ".kpi{\n",
       "  background:var(--card); border:1px solid rgba(255,255,255,.06);\n",
       "  border-radius:12px; padding:12px;\n",
       "}\n",
       ".kpi .label{ color:var(--muted); font-size:12px; }\n",
       ".kpi .value{ font-size:22px; font-weight:600; color:var(--accent); }\n",
       ".tbl-title{ font-size:14px; font-weight:600; margin:12px 0 6px 0; }\n",
       ".footer-note{ color:var(--muted); font-size:12px; margin-top:8px; }\n",
       "</style>\n",
       "<div class=\"app-wrap\"><div class=\"app-title\">Analyse DVF — Île-de-France</div><div class=\"app-subtitle\">Nettoyage, filtres interactifs & exploration</div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73171ec34d3434297b9a64070475a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='<div class=\"app-wrap\" style=\"width:16px;visibility:hidden\"></div>'), VBox(children=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ============================= Dashboard esthétique (widgets + UI) =============================\n",
    "import ipywidgets as W\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# -- Thème & helpers UI -------------------------------------------------------------------------\n",
    "CSS = \"\"\"\n",
    "<style>\n",
    ":root{\n",
    "  --bg:#0f172a;         /* slate-900 */\n",
    "  --panel:#111827;      /* gray-900 */\n",
    "  --card:#131a2a;       /* custom */\n",
    "  --muted:#9ca3af;      /* gray-400 */\n",
    "  --text:#e5e7eb;       /* gray-200 */\n",
    "  --accent:#22d3ee;     /* cyan-400 */\n",
    "  --accent2:#60a5fa;    /* blue-400 */\n",
    "}\n",
    "div.app-wrap{\n",
    "  background:linear-gradient(135deg,#0f172a 0%,#0b1220 100%);\n",
    "  color:var(--text);\n",
    "  padding:16px 16px 24px 16px; border-radius:16px;\n",
    "  box-shadow:0 10px 30px rgba(0,0,0,.35);\n",
    "  font-family: ui-sans-serif, system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, Helvetica Neue, Arial;\n",
    "}\n",
    ".app-title{\n",
    "  font-size:20px; font-weight:600; letter-spacing:.2px; margin:0 0 8px 0;\n",
    "}\n",
    ".app-subtitle{\n",
    "  color:var(--muted); font-size:13px; margin:0 0 14px 0;\n",
    "}\n",
    ".grid-2{\n",
    "  display:grid; grid-template-columns: 1.1fr 1fr; gap:16px; align-items:start;\n",
    "}\n",
    ".card{\n",
    "  background:var(--panel); border:1px solid rgba(255,255,255,.06);\n",
    "  border-radius:14px; padding:12px 12px;\n",
    "}\n",
    ".controls-grid{\n",
    "  display:grid; grid-template-columns:1fr 1fr; gap:10px;\n",
    "}\n",
    ".kpis{ display:grid; grid-template-columns: repeat(3, 1fr); gap:10px; }\n",
    ".kpi{\n",
    "  background:var(--card); border:1px solid rgba(255,255,255,.06);\n",
    "  border-radius:12px; padding:12px;\n",
    "}\n",
    ".kpi .label{ color:var(--muted); font-size:12px; }\n",
    ".kpi .value{ font-size:22px; font-weight:600; color:var(--accent); }\n",
    ".tbl-title{ font-size:14px; font-weight:600; margin:12px 0 6px 0; }\n",
    ".footer-note{ color:var(--muted); font-size:12px; margin-top:8px; }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "def fmt_int(x):\n",
    "    return f\"{int(x):,}\".replace(\",\", \" \")\n",
    "\n",
    "def kpi_card(label, value_html):\n",
    "    return f\"\"\"\n",
    "    <div class=\"kpi\">\n",
    "      <div class=\"label\">{label}</div>\n",
    "      <div class=\"value\">{value_html}</div>\n",
    "    </div>\n",
    "    \"\"\"\n",
    "\n",
    "display(HTML(CSS + '<div class=\"app-wrap\"><div class=\"app-title\">Analyse DVF — Île-de-France</div><div class=\"app-subtitle\">Nettoyage, filtres interactifs & exploration</div></div>'))\n",
    "\n",
    "# -- Données -------------------------------------------------------------------------------------\n",
    "df = pd.read_parquet(clean_fp).copy()\n",
    "# sécurité colonnes\n",
    "for c in [\"prix_m2\",\"surface_reelle_bati\",\"valeur_fonciere\", \"annee\", \"nom_commune\", \"code_postal\"]:\n",
    "    if c not in df.columns:\n",
    "        df[c] = np.nan\n",
    "\n",
    "# -- Widgets -------------------------------------------------------------------------------------\n",
    "w_surface = W.IntRangeSlider(value=(20, 80), min=10, max=200, step=1,\n",
    "                             description=\"Surface (m²)\", continuous_update=False, readout=True,\n",
    "                             style={'description_width':'110px'}, layout=W.Layout(width='100%'))\n",
    "w_loyer   = W.FloatSlider(value=22.0, min=5.0, max=45.0, step=0.5,\n",
    "                          readout_format=\".1f\", description=\"Loyer €/m²\", continuous_update=False,\n",
    "                          style={'description_width':'110px'}, layout=W.Layout(width='100%'))\n",
    "w_topn    = W.IntSlider(value=15, min=5, max=50, step=1,\n",
    "                        description=\"Top N\", continuous_update=False,\n",
    "                        style={'description_width':'110px'}, layout=W.Layout(width='100%'))\n",
    "w_iqr     = W.ToggleButtons(options=[('IQR on', True), ('IQR off', False)],\n",
    "                            value=True, description=\"Outliers\",\n",
    "                            style={'description_width':'110px'})\n",
    "w_hist    = W.Checkbox(value=True, description=\"Histogramme prix/m²\")\n",
    "w_year    = W.SelectionRangeSlider(\n",
    "              options=sorted(df[\"annee\"].dropna().astype(int).unique()),\n",
    "              index=(0, max(0, len(df[\"annee\"].dropna().unique())-1)),\n",
    "              description=\"Années\", continuous_update=False,\n",
    "              layout=W.Layout(width='100%'),\n",
    "              style={'description_width':'110px'}\n",
    "           ) if df[\"annee\"].notna().any() else W.Label(\"Années : n/a\")\n",
    "\n",
    "communes = [\"(Toutes)\"] + sorted(df[\"nom_commune\"].dropna().astype(str).unique().tolist())\n",
    "w_commune = W.Dropdown(options=communes, value=\"(Toutes)\", description=\"Commune\",\n",
    "                       layout=W.Layout(width='100%'), style={'description_width':'110px'})\n",
    "\n",
    "w_btn_export = W.Button(description=\"Exporter (CSV)\", button_style='',\n",
    "                        tooltip=\"Exporte le dataset filtré en CSV dans le dossier clean/\",\n",
    "                        layout=W.Layout(width='160px'))\n",
    "w_msg = W.HTML(\"\")\n",
    "\n",
    "# -- Sorties -------------------------------------------------------------------------------------\n",
    "out_overview = W.Output()\n",
    "out_table    = W.Output()\n",
    "out_plot1    = W.Output()\n",
    "out_plot2    = W.Output()\n",
    "\n",
    "# -- Filtres & calculs ---------------------------------------------------------------------------\n",
    "def iqr_bounds(s, k=2.0):\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    return q1 - k*iqr, q3 + k*iqr\n",
    "\n",
    "def apply_filters(d):\n",
    "    # surface\n",
    "    smin, smax = w_surface.value\n",
    "    d = d[d[\"surface_reelle_bati\"].between(smin, smax)]\n",
    "    # années\n",
    "    if isinstance(w_year, W.SelectionRangeSlider):\n",
    "        y0, y1 = w_year.value\n",
    "        d = d[(d[\"annee\"]>=y0) & (d[\"annee\"]<=y1)]\n",
    "    # commune\n",
    "    if w_commune.value != \"(Toutes)\":\n",
    "        d = d[d[\"nom_commune\"] == w_commune.value]\n",
    "    # outliers\n",
    "    if w_iqr.value and len(d) >= 50 and d[\"prix_m2\"].notna().any():\n",
    "        lo, hi = iqr_bounds(d[\"prix_m2\"], k=2.0)\n",
    "        d = d[d[\"prix_m2\"].between(lo, hi)]\n",
    "    # yield\n",
    "    loyer_m2 = w_loyer.value\n",
    "    d = d.assign(revenu_annuel = loyer_m2 * d[\"surface_reelle_bati\"] * 12.0)\n",
    "    d = d.assign(yield_brut = d[\"revenu_annuel\"] / d[\"valeur_fonciere\"])\n",
    "    return d\n",
    "\n",
    "# -- Rendu ---------------------------------------------------------------------------------------\n",
    "def render(_=None):\n",
    "    with out_overview:\n",
    "        clear_output(wait=True)\n",
    "        d = apply_filters(df)\n",
    "\n",
    "        nb = len(d)\n",
    "        p50 = float(d[\"prix_m2\"].median()) if d[\"prix_m2\"].notna().any() else np.nan\n",
    "        ymd = float(d[\"yield_brut\"].median()) if d[\"yield_brut\"].notna().any() else np.nan\n",
    "        s50 = float(d[\"surface_reelle_bati\"].median()) if d[\"surface_reelle_bati\"].notna().any() else np.nan\n",
    "\n",
    "        kpis_html = '<div class=\"kpis\">' + \\\n",
    "            kpi_card(\"Transactions\", fmt_int(nb) if nb==nb else \"–\") + \\\n",
    "            kpi_card(\"Prix/m² médiane\", f\"{p50:,.0f} €\".replace(\",\", \" \") if p50==p50 else \"–\") + \\\n",
    "            kpi_card(\"Rendement brut médian\", f\"{ymd*100:,.1f} %\".replace(\",\", \" \") if ymd==ymd else \"–\") + \\\n",
    "        '</div>'\n",
    "\n",
    "        display(HTML(f'<div class=\"card\">{kpis_html}<div class=\"footer-note\">Filtrage interactif à gauche. Export CSV disponible.</div></div>'))\n",
    "\n",
    "    with out_table:\n",
    "        clear_output(wait=True)\n",
    "        d = apply_filters(df)\n",
    "        # Top N communes par rendement médian\n",
    "        if len(d):\n",
    "            top = (d.groupby([\"nom_commune\",\"code_postal\"], as_index=False)[\"yield_brut\"]\n",
    "                     .median().sort_values(\"yield_brut\", ascending=False).head(w_topn.value))\n",
    "            top[\"yield_brut_%\"] = (top[\"yield_brut\"]*100).round(2)\n",
    "            to_show = top[[\"nom_commune\",\"code_postal\",\"yield_brut_%\"]].rename(\n",
    "                columns={\"nom_commune\":\"Commune\",\"code_postal\":\"CP\",\"yield_brut_%\":\"Yield brut (%)\"}\n",
    "            )\n",
    "            html = to_show.style.hide(axis=\"index\") \\\n",
    "                               .set_table_styles([{'selector':'th','props':'text-align:left; padding:6px 8px;'},\n",
    "                                                  {'selector':'td','props':'padding:6px 8px;'}]) \\\n",
    "                               .bar(subset=[\"Yield brut (%)\"], vmin=to_show[\"Yield brut (%)\"].min(),\n",
    "                                    vmax=to_show[\"Yield brut (%)\"].max()) \\\n",
    "                               .to_html()\n",
    "            display(HTML('<div class=\"tbl-title\">Top communes (médiane du rendement)</div>'))\n",
    "            display(HTML(f'<div class=\"card\">{html}</div>'))\n",
    "        else:\n",
    "            display(HTML('<div class=\"card\">Aucune donnée avec ces filtres.</div>'))\n",
    "\n",
    "    # Graphes: Plotly si possible, sinon Matplotlib\n",
    "    try:\n",
    "        import plotly.express as px\n",
    "        with out_plot1:\n",
    "            clear_output(wait=True)\n",
    "            d = apply_filters(df)\n",
    "            if len(d):\n",
    "                ds = d.sample(min(4000, len(d)), random_state=0)\n",
    "                fig = px.scatter(ds, x=\"surface_reelle_bati\", y=\"prix_m2\",\n",
    "                                 hover_data=[\"nom_commune\",\"code_postal\",\"annee\"],\n",
    "                                 trendline=\"lowess\", height=420)\n",
    "                fig.update_layout(margin=dict(l=10,r=10,t=10,b=10), template=\"plotly_dark\")\n",
    "                fig.show()\n",
    "            else:\n",
    "                display(HTML('<div class=\"card\">—</div>'))\n",
    "\n",
    "        with out_plot2:\n",
    "            clear_output(wait=True)\n",
    "            d = apply_filters(df)\n",
    "            if len(d) and w_hist.value and d[\"prix_m2\"].notna().any():\n",
    "                cut = d[\"prix_m2\"].clip(upper=d[\"prix_m2\"].quantile(0.99))\n",
    "                fig = px.histogram(cut, x=cut, nbins=45, height=380)\n",
    "                fig.update_layout(margin=dict(l=10,r=10,t=10,b=10), template=\"plotly_dark\")\n",
    "                fig.update_xaxes(title=\"Prix/m² (€)\")\n",
    "                fig.update_yaxes(title=\"Fréquence\")\n",
    "                fig.show()\n",
    "            else:\n",
    "                display(HTML('<div class=\"card\">—</div>'))\n",
    "\n",
    "    except Exception:\n",
    "        with out_plot1:\n",
    "            clear_output(wait=True)\n",
    "            d = apply_filters(df)\n",
    "            if len(d):\n",
    "                ds = d.sample(min(4000, len(d)), random_state=0)\n",
    "                plt.figure(figsize=(6.8,4.2))\n",
    "                plt.scatter(ds[\"surface_reelle_bati\"], ds[\"prix_m2\"], s=12, alpha=.6)\n",
    "                plt.title(\"Prix/m² vs Surface (échantillon)\")\n",
    "                plt.xlabel(\"Surface (m²)\"); plt.ylabel(\"Prix/m² (€)\")\n",
    "                plt.grid(alpha=.2); plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                display(HTML('<div class=\"card\">—</div>'))\n",
    "\n",
    "        with out_plot2:\n",
    "            clear_output(wait=True)\n",
    "            d = apply_filters(df)\n",
    "            if len(d) and w_hist.value and d[\"prix_m2\"].notna().any():\n",
    "                cut = d[\"prix_m2\"].clip(upper=d[\"prix_m2\"].quantile(0.99))\n",
    "                plt.figure(figsize=(6.8,3.8))\n",
    "                plt.hist(cut, bins=45)\n",
    "                plt.title(\"Distribution du prix/m² (troncature 99e centile)\")\n",
    "                plt.xlabel(\"Prix/m² (€)\"); plt.ylabel(\"Fréquence\")\n",
    "                plt.grid(alpha=.2); plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                display(HTML('<div class=\"card\">—</div>'))\n",
    "\n",
    "# -- Export CSV ----------------------------------------------------------------------------------\n",
    "def on_export_clicked(_):\n",
    "    d = apply_filters(df)\n",
    "    out_fp = os.path.join(CLEAN_DIR, \"dvf_filtre_export.csv\")\n",
    "    d.to_csv(out_fp, index=False)\n",
    "    w_msg.value = f'<span style=\"color:#22d3ee\">Exporté : {out_fp}</span>'\n",
    "\n",
    "w_btn_export.on_click(on_export_clicked)\n",
    "\n",
    "# -- Mise en page (onglets) ----------------------------------------------------------------------\n",
    "controls_left = W.VBox([\n",
    "    W.HTML('<div class=\"card\"><div class=\"controls-grid\"></div></div>'),  # placeholder css card\n",
    "    W.VBox([\n",
    "        W.HTML('<div class=\"card\"><div class=\"app-subtitle\" style=\"margin:0 0 10px 0;\">Paramètres</div>'),\n",
    "        W.VBox([\n",
    "            w_surface, w_loyer, w_topn, w_iqr, w_hist, w_year, w_commune,\n",
    "            W.HBox([w_btn_export, w_msg])\n",
    "        ], layout=W.Layout(padding=\"0 6px 8px 6px\"))\n",
    "    ])\n",
    "])\n",
    "\n",
    "tab = W.Tab(children=[\n",
    "    W.VBox([out_overview]),\n",
    "    W.VBox([out_table]),\n",
    "    W.VBox([out_plot1]),\n",
    "    W.VBox([out_plot2]),\n",
    "])\n",
    "tab.set_title(0, \"Vue d’ensemble\")\n",
    "tab.set_title(1, \"Communes\")\n",
    "tab.set_title(2, \"Dispersion\")\n",
    "tab.set_title(3, \"Distribution\")\n",
    "\n",
    "layout = W.HBox([\n",
    "    W.HTML('<div class=\"app-wrap\" style=\"width:16px;visibility:hidden\"></div>'),\n",
    "    W.VBox([controls_left], layout=W.Layout(min_width=\"360px\", width=\"380px\")),\n",
    "    W.VBox([tab], layout=W.Layout(flex=\"1 1 auto\", width=\"100%\"))\n",
    "])\n",
    "display(layout)\n",
    "\n",
    "# -- Observers -----------------------------------------------------------------------------------\n",
    "for w in (w_surface, w_loyer, w_topn, w_iqr, w_hist, w_commune):\n",
    "    w.observe(render, \"value\")\n",
    "if isinstance(w_year, W.SelectionRangeSlider):\n",
    "    w_year.observe(render, \"value\")\n",
    "\n",
    "render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed903374",
   "metadata": {},
   "source": [
    "## Chargement + typage + IDF + prix/m²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3dbc1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CODES -> (35007, 4) ['code_commune_insee', 'code_postal', 'nom_commune', 'libelle_acheminement']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code_commune_insee</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>nom_commune</th>\n",
       "      <th>libelle_acheminement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>01400</td>\n",
       "      <td>L ABERGEMENT CLEMENCIAT</td>\n",
       "      <td>L ABERGEMENT CLEMENCIAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01002</td>\n",
       "      <td>01640</td>\n",
       "      <td>L ABERGEMENT DE VAREY</td>\n",
       "      <td>L ABERGEMENT DE VAREY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01004</td>\n",
       "      <td>01500</td>\n",
       "      <td>AMBERIEU EN BUGEY</td>\n",
       "      <td>AMBERIEU EN BUGEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01005</td>\n",
       "      <td>01330</td>\n",
       "      <td>AMBERIEUX EN DOMBES</td>\n",
       "      <td>AMBERIEUX EN DOMBES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01006</td>\n",
       "      <td>01300</td>\n",
       "      <td>AMBLEON</td>\n",
       "      <td>AMBLEON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code_commune_insee code_postal              nom_commune  \\\n",
       "0              01001       01400  L ABERGEMENT CLEMENCIAT   \n",
       "1              01002       01640    L ABERGEMENT DE VAREY   \n",
       "2              01004       01500        AMBERIEU EN BUGEY   \n",
       "3              01005       01330      AMBERIEUX EN DOMBES   \n",
       "4              01006       01300                  AMBLEON   \n",
       "\n",
       "      libelle_acheminement  \n",
       "0  L ABERGEMENT CLEMENCIAT  \n",
       "1    L ABERGEMENT DE VAREY  \n",
       "2        AMBERIEU EN BUGEY  \n",
       "3      AMBERIEUX EN DOMBES  \n",
       "4                  AMBLEON  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, re, unicodedata as ud\n",
    "import pandas as pd\n",
    "\n",
    "CLEAN_DIR = os.path.abspath(os.path.join(\"..\", \"data\", \"clean\"))\n",
    "os.makedirs(CLEAN_DIR, exist_ok=True)\n",
    "codes_parquet = os.path.join(CLEAN_DIR, \"codes_postaux.parquet\")\n",
    "\n",
    "def _norm_name(c: str) -> str:\n",
    "    # normalise: strip, retire '#', enlève accents, lower, remplace non-alnum par '_', compresse '__'\n",
    "    c = (c or \"\").strip().lstrip(\"#\")\n",
    "    c = ud.normalize(\"NFKD\", c).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    c = re.sub(r\"[^A-Za-z0-9]+\", \"_\", c).strip(\"_\").lower()\n",
    "    c = re.sub(r\"_+\", \"_\", c)\n",
    "    return c\n",
    "\n",
    "def _find_col(cols, candidates):\n",
    "    \"\"\"retourne le premier nom présent parmi les 'candidates' (déjà normalisés)\"\"\"\n",
    "    for cand in candidates:\n",
    "        if cand in cols:\n",
    "            return cand\n",
    "    return None\n",
    "\n",
    "def read_codes_postaux_robust(path, cache_fp=codes_parquet, force_reload=False):\n",
    "    # 0) Cache parquet ultra-rapide\n",
    "    if os.path.exists(cache_fp) and not force_reload:\n",
    "        dfp = pd.read_parquet(cache_fp)\n",
    "        # vérifie qu'on a bien l'INSEE\n",
    "        if \"code_commune_insee\" in dfp.columns:\n",
    "            return dfp\n",
    "\n",
    "    # 1) Lecture rapide (moteur C) – encodage cp1252 (classique), sinon latin-1\n",
    "    try:\n",
    "        raw = pd.read_csv(path, sep=\";\", dtype=str, encoding=\"cp1252\", engine=\"c\", low_memory=True)\n",
    "    except UnicodeDecodeError:\n",
    "        raw = pd.read_csv(path, sep=\";\", dtype=str, encoding=\"latin-1\", engine=\"c\", low_memory=True)\n",
    "\n",
    "    # 2) Normalise tous les noms de colonnes\n",
    "    norm_cols = [_norm_name(c) for c in raw.columns]\n",
    "    raw.columns = norm_cols\n",
    "    cols = set(norm_cols)\n",
    "\n",
    "    # 3) Détection robuste des colonnes utiles\n",
    "    insee_col = _find_col(cols, [\"code_commune_insee\", \"code_insee_commune\", \"codeinsee\", \"insee\", \"code_commune\"])\n",
    "    cp_col    = _find_col(cols, [\"code_postal\", \"cp\", \"codepostal\"])\n",
    "    nom_col   = _find_col(cols, [\"nom_de_la_commune\", \"nom_commune\", \"commune\", \"nom\"])\n",
    "    lib_col   = _find_col(cols, [\"libelle_d_acheminement\", \"libelle_acheminement\", \"libelle_d_acheminement\"])\n",
    "    l5_col    = _find_col(cols, [\"ligne_5\", \"ligne5\"])\n",
    "\n",
    "    if insee_col is None:\n",
    "        # aide au debug : affiche les colonnes rencontrées\n",
    "        raise KeyError(\n",
    "            \"Impossible de trouver la colonne INSEE. Colonnes normalisées lues : \"\n",
    "            + \", \".join(sorted(cols))\n",
    "        )\n",
    "\n",
    "    # 4) Sous-sélection & renommage stable\n",
    "    keep_map = {}\n",
    "    keep_map[insee_col] = \"code_commune_insee\"\n",
    "    if cp_col:  keep_map[cp_col]  = \"code_postal\"\n",
    "    if nom_col: keep_map[nom_col] = \"nom_commune\"\n",
    "    if lib_col: keep_map[lib_col] = \"libelle_acheminement\"\n",
    "    if l5_col:  keep_map[l5_col]  = \"ligne_5\"\n",
    "\n",
    "    df = raw[list(keep_map.keys())].rename(columns=keep_map)\n",
    "\n",
    "    # 5) Formats\n",
    "    df[\"code_commune_insee\"] = df[\"code_commune_insee\"].astype(str).str.strip().str.zfill(5)\n",
    "    if \"code_postal\" in df.columns:\n",
    "        df[\"code_postal\"] = df[\"code_postal\"].astype(str).str.strip().str.zfill(5)\n",
    "\n",
    "    # 6) Réduction à 1 ligne par INSEE (code postal “référence” choisi par ordre)\n",
    "    # 6) Réduction à 1 ligne par INSEE (choix d’un code postal “référence” par ordre)\n",
    "    agg_dict = {}\n",
    "    if \"code_postal\" in df.columns:\n",
    "        agg_dict[\"code_postal\"] = \"first\"\n",
    "    if \"nom_commune\" in df.columns:\n",
    "        agg_dict[\"nom_commune\"] = \"first\"\n",
    "    if \"libelle_acheminement\" in df.columns:\n",
    "        agg_dict[\"libelle_acheminement\"] = \"first\"\n",
    "\n",
    "    # Si aucune colonne à agréger n'est dispo, on garde juste la liste unique des INSEE\n",
    "    if not agg_dict:\n",
    "        df_ref = df[[\"code_commune_insee\"]].drop_duplicates().copy()\n",
    "    else:\n",
    "        sort_cols = [\"code_commune_insee\"] + ([\"code_postal\"] if \"code_postal\" in df.columns else [])\n",
    "        df_ref = (\n",
    "            df.sort_values(sort_cols)\n",
    "            .groupby(\"code_commune_insee\", as_index=False)\n",
    "            .agg(agg_dict)                # <-- dict, pas **kwargs\n",
    "        )\n",
    "\n",
    "    df_ref.to_parquet(cache_fp, index=False)\n",
    "    return df_ref\n",
    "codes = read_codes_postaux_robust(codes_csv, force_reload=True)\n",
    "print(\"CODES ->\", codes.shape, list(codes.columns))\n",
    "codes.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5b3f3",
   "metadata": {},
   "source": [
    "## Lecture de la base codes postaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f94f21b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dvf_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 92\u001b[39m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df_min\n\u001b[32m     91\u001b[39m clean_fp = os.path.join(CLEAN_DIR, \u001b[33m\"\u001b[39m\u001b[33mdvf_clean.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m dvf = load_dvf_chunked(\u001b[43mdvf_txt\u001b[49m, clean_fp)\n\u001b[32m     93\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDVF ->\u001b[39m\u001b[33m\"\u001b[39m, dvf.shape, \u001b[38;5;28mlist\u001b[39m(dvf.columns))\n",
      "\u001b[31mNameError\u001b[39m: name 'dvf_txt' is not defined"
     ]
    }
   ],
   "source": [
    "def load_dvf_chunked(dvf_path, clean_fp):\n",
    "    # Si un parquet propre existe déjà : le lire directement (plus rapide)\n",
    "    if os.path.exists(clean_fp):\n",
    "        df = pd.read_parquet(clean_fp)\n",
    "        return df\n",
    "\n",
    "    usecols = [\n",
    "        \"Date mutation\",\"Nature mutation\",\"Valeur fonciere\",\n",
    "        \"Code postal\",\"Commune\",\"Code departement\",\"Code commune\",\n",
    "        \"Type local\",\"Surface reelle bati\",\"Nombre pieces principales\"\n",
    "    ]\n",
    "    idf_prefix = (\"75\",\"77\",\"78\",\"91\",\"92\",\"93\",\"94\",\"95\")\n",
    "\n",
    "    keep = []\n",
    "    chunksize = 200_000\n",
    "    # encodage DVF souvent cp1252\n",
    "    for i, chunk in enumerate(pd.read_csv(\n",
    "        dvf_path, sep=\"|\", dtype=str, usecols=usecols,\n",
    "        chunksize=chunksize, low_memory=True, engine=\"c\", encoding=\"cp1252\"\n",
    "    )):\n",
    "        # vente + IDF\n",
    "        chunk = chunk[chunk[\"Nature mutation\"].fillna(\"\").str.contains(\"Vente\", case=False, na=False)]\n",
    "        chunk = chunk[chunk[\"Code departement\"].astype(str).str.startswith(idf_prefix)]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # num + filtres\n",
    "        chunk[\"Valeur fonciere\"] = to_num_fr(chunk[\"Valeur fonciere\"])\n",
    "        chunk[\"Surface reelle bati\"] = pd.to_numeric(chunk[\"Surface reelle bati\"], errors=\"coerce\")\n",
    "\n",
    "        chunk = chunk[(chunk[\"Surface reelle bati\"] > 8) & (chunk[\"Valeur fonciere\"] > 1000)]\n",
    "        chunk[\"prix_m2\"] = chunk[\"Valeur fonciere\"] / chunk[\"Surface reelle bati\"]\n",
    "        chunk = chunk[chunk[\"prix_m2\"].between(100, 30000)]\n",
    "\n",
    "        # dates + renommage\n",
    "        chunk[\"Date mutation\"] = pd.to_datetime(chunk[\"Date mutation\"], errors=\"coerce\")\n",
    "        chunk = chunk.rename(columns={\n",
    "            \"Date mutation\":\"date_mutation\",\n",
    "            \"Valeur fonciere\":\"valeur_fonciere\",\n",
    "            \"Surface reelle bati\":\"surface_reelle_bati\",\n",
    "            \"Commune\":\"nom_commune\",\n",
    "            \"Code postal\":\"code_postal\",\n",
    "            \"Type local\":\"type_local\",\n",
    "            \"Code departement\":\"code_departement\",\n",
    "            \"Code commune\":\"code_commune_3\"\n",
    "        })\n",
    "\n",
    "        # construire code INSEE (dept 2 + commune 3) — valable en IDF\n",
    "        chunk[\"code_departement\"] = chunk[\"code_departement\"].astype(str).str.strip().str.zfill(2)\n",
    "        chunk[\"code_commune_3\"]  = chunk[\"code_commune_3\"].astype(str).str.strip().str.zfill(3)\n",
    "        chunk[\"code_commune_insee\"] = chunk[\"code_departement\"] + chunk[\"code_commune_3\"]\n",
    "\n",
    "        keep.append(chunk[[\n",
    "            \"date_mutation\",\"valeur_fonciere\",\"surface_reelle_bati\",\"prix_m2\",\n",
    "            \"nom_commune\",\"code_postal\",\"type_local\",\"code_commune_insee\"\n",
    "        ]])\n",
    "\n",
    "        if (i+1) % 5 == 0:\n",
    "            print(f\"[Progression] {i+1} chunks traités...\")\n",
    "\n",
    "    if not keep:\n",
    "        raise RuntimeError(\"Aucune ligne DVF retenue après filtrage.\")\n",
    "\n",
    "    df = pd.concat(keep, ignore_index=True)\n",
    "    df[\"annee\"] = pd.to_datetime(df[\"date_mutation\"], errors=\"coerce\").dt.year\n",
    "\n",
    "    # Merge codes postaux via INSEE → 1 ligne par INSEE côté référentiel\n",
    "    codes_ref = (codes\n",
    "                 .dropna(subset=[\"code_commune_insee\"])\n",
    "                 .sort_values([\"code_commune_insee\",\"code_postal\"])\n",
    "                 .groupby(\"code_commune_insee\", as_index=False)\n",
    "                 .agg(code_postal_ref=(\"code_postal\",\"first\"),\n",
    "                      nom_commune_ref=(\"nom_commune\",\"first\"),\n",
    "                      libelle_acheminement_ref=(\"libelle_acheminement\",\"first\")))\n",
    "\n",
    "    df = df.merge(codes_ref, on=\"code_commune_insee\", how=\"left\")\n",
    "    # harmoniser nom_commune si manquants\n",
    "    if \"nom_commune\" not in df.columns or df[\"nom_commune\"].isna().mean() > 0.5:\n",
    "        df[\"nom_commune\"] = df[\"nom_commune_ref\"].fillna(df.get(\"nom_commune\", pd.Series(index=df.index)))\n",
    "\n",
    "    # colonnes finales minimales\n",
    "    df_min = df[[\n",
    "        \"date_mutation\",\"annee\",\"valeur_fonciere\",\"surface_reelle_bati\",\"prix_m2\",\n",
    "        \"nom_commune\",\"code_commune_insee\",\"code_postal_ref\"\n",
    "    ]].rename(columns={\"code_postal_ref\":\"code_postal\"})\n",
    "\n",
    "    df_min.to_parquet(clean_fp, index=False)\n",
    "    print(f\"[OK] Sauvegardé → {clean_fp} ({len(df_min):,} lignes)\")\n",
    "    return df_min\n",
    "\n",
    "clean_fp = os.path.join(CLEAN_DIR, \"dvf_clean.parquet\")\n",
    "dvf = load_dvf_chunked(dvf_txt, clean_fp)\n",
    "print(\"DVF ->\", dvf.shape, list(dvf.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c771235d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "clean_fp = os.path.join(\"..\", \"data\", \"clean\", \"dvf_clean.parquet\")\n",
    "if os.path.exists(clean_fp):\n",
    "    os.remove(clean_fp)\n",
    "    print(\"Deleted:\", clean_fp)\n",
    "import os, pandas as pd\n",
    "\n",
    "RAW_DIR   = os.path.abspath(os.path.join(\"..\", \"data\", \"raw\"))\n",
    "CLEAN_DIR = os.path.abspath(os.path.join(\"..\", \"data\", \"clean\"))\n",
    "os.makedirs(CLEAN_DIR, exist_ok=True)\n",
    "\n",
    "raw_txt  = os.path.join(RAW_DIR, \"DVF_2025_S1.txt\")\n",
    "clean_fp = os.path.join(CLEAN_DIR, \"dvf_clean.parquet\")\n",
    "\n",
    "def to_num_fr(s: pd.Series) -> pd.Series:\n",
    "    s = s.astype(str).str.replace(\"\\u00A0\",\"\", regex=False)  # NBSP\n",
    "    s = s.str.replace(\" \", \"\", regex=False).str.replace(\",\", \".\", regex=False)\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def load_dvf_chunked(dvf_path=raw_txt, out_fp=clean_fp):\n",
    "    if os.path.exists(out_fp):\n",
    "        return pd.read_parquet(out_fp)\n",
    "\n",
    "    usecols = [\n",
    "        \"Date mutation\",\"Nature mutation\",\"Valeur fonciere\",\n",
    "        \"Code postal\",\"Commune\",\"Code departement\",\"Code commune\",\n",
    "        \"Type local\",\"Surface reelle bati\",\"Nombre pieces principales\"\n",
    "    ]\n",
    "    idf_prefix = (\"75\",\"77\",\"78\",\"91\",\"92\",\"93\",\"94\",\"95\")\n",
    "    chunksize = 200_000\n",
    "    keep = []\n",
    "\n",
    "    # Try UTF-8 first (file shows UTF-8 symptoms), then fallback CP1252\n",
    "    tried = []\n",
    "    for enc in (\"utf-8\", \"cp1252\"):\n",
    "        try:\n",
    "            reader = pd.read_csv(\n",
    "                dvf_path, sep=\"|\", dtype=str, usecols=usecols,\n",
    "                chunksize=chunksize, low_memory=True, engine=\"c\", encoding=enc\n",
    "            )\n",
    "            tried.append(enc)\n",
    "            for i, chunk in enumerate(reader):\n",
    "                # Filter Vente + IDF early\n",
    "                chunk = chunk[chunk[\"Nature mutation\"].fillna(\"\").str.contains(\"Vente\", case=False, na=False)]\n",
    "                chunk = chunk[chunk[\"Code departement\"].astype(str).str.startswith(idf_prefix)]\n",
    "                if chunk.empty:\n",
    "                    continue\n",
    "\n",
    "                # Numeric conversions\n",
    "                chunk[\"Valeur fonciere\"]     = to_num_fr(chunk[\"Valeur fonciere\"])\n",
    "                chunk[\"Surface reelle bati\"] = pd.to_numeric(chunk[\"Surface reelle bati\"], errors=\"coerce\")\n",
    "\n",
    "                # Date parse — explicit dd/mm/yyyy\n",
    "                dm = chunk[\"Date mutation\"].astype(str).str.strip()\n",
    "                dt = pd.to_datetime(dm, format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "                # Small fallback for rare ISO rows (yyyy-mm-dd)\n",
    "                m = dt.isna()\n",
    "                if m.any():\n",
    "                    dt.loc[m] = pd.to_datetime(dm.loc[m], errors=\"coerce\", dayfirst=True)\n",
    "                chunk[\"Date mutation\"] = dt\n",
    "\n",
    "                # Keep only plausible values\n",
    "                chunk = chunk[(chunk[\"Surface reelle bati\"] > 8) & (chunk[\"Valeur fonciere\"] > 1000)]\n",
    "                chunk[\"prix_m2\"] = chunk[\"Valeur fonciere\"] / chunk[\"Surface reelle bati\"]\n",
    "                chunk = chunk[chunk[\"prix_m2\"].between(100, 30000)]\n",
    "\n",
    "                # Build INSEE key (IDF => dept 2 + commune 3)\n",
    "                chunk = chunk.rename(columns={\n",
    "                    \"Date mutation\":\"date_mutation\",\n",
    "                    \"Valeur fonciere\":\"valeur_fonciere\",\n",
    "                    \"Surface reelle bati\":\"surface_reelle_bati\",\n",
    "                    \"Commune\":\"nom_commune\",\n",
    "                    \"Code postal\":\"code_postal\",\n",
    "                    \"Type local\":\"type_local\",\n",
    "                    \"Code departement\":\"code_departement\",\n",
    "                    \"Code commune\":\"code_commune_3\"\n",
    "                })\n",
    "                chunk[\"code_departement\"]   = chunk[\"code_departement\"].astype(str).str.strip().str.zfill(2)\n",
    "                chunk[\"code_commune_3\"]     = chunk[\"code_commune_3\"].astype(str).str.strip().str.zfill(3)\n",
    "                chunk[\"code_commune_insee\"] = chunk[\"code_departement\"] + chunk[\"code_commune_3\"]\n",
    "\n",
    "                keep.append(chunk[[\n",
    "                    \"date_mutation\",\"valeur_fonciere\",\"surface_reelle_bati\",\"prix_m2\",\n",
    "                    \"nom_commune\",\"code_postal\",\"type_local\",\"code_commune_insee\"\n",
    "                ]])\n",
    "\n",
    "                if (i+1) % 5 == 0:\n",
    "                    print(f\"[{enc}] chunks: {i+1}  rows kept: ~{sum(len(k) for k in keep):,}\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            tried.append(f\"{enc} (failed: {e.__class__.__name__})\")\n",
    "            continue\n",
    "\n",
    "    if not keep:\n",
    "        raise RuntimeError(f\"DVF read yielded no rows. Tried encodings: {tried}\")\n",
    "\n",
    "    df = pd.concat(keep, ignore_index=True)\n",
    "    df[\"annee\"] = pd.to_datetime(df[\"date_mutation\"], errors=\"coerce\").dt.year\n",
    "    df.to_parquet(out_fp, index=False)\n",
    "    print(f\"[OK] Saved → {out_fp}  rows={len(df):,}\")\n",
    "    return df\n",
    "\n",
    "dvf = load_dvf_chunked()\n",
    "print(dvf.shape, dvf[\"date_mutation\"].isna().mean(), dvf[\"annee\"].isna().mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad7ad79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def parse_dates_robust(s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Nettoyage + parsing multi-formats pour DVF date_mutation.\"\"\"\n",
    "    # 1) Normalise la chaîne (retire NBSP, trim, garde chiffres et /-)\n",
    "    x = (s.astype(str)\n",
    "           .str.replace(\"\\u00A0\",\" \", regex=False)   # NBSP\n",
    "           .str.strip()\n",
    "           .str.replace(r\"[^0-9/\\-]\", \"\", regex=True))\n",
    "\n",
    "    out = pd.Series(pd.NaT, index=s.index, dtype=\"datetime64[ns]\")\n",
    "\n",
    "    # 2) yyyy-mm-dd\n",
    "    m1 = x.str.match(r\"^\\d{4}-\\d{2}-\\d{2}$\", na=False)\n",
    "    if m1.any():\n",
    "        out.loc[m1] = pd.to_datetime(x.loc[m1], format=\"%Y-%m-%d\", errors=\"coerce\")\n",
    "\n",
    "    # 3) dd/mm/yyyy\n",
    "    m2 = x.str.match(r\"^\\d{1,2}/\\d{1,2}/\\d{4}$\", na=False)\n",
    "    if m2.any():\n",
    "        out.loc[m2] = pd.to_datetime(x.loc[m2], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "    # 4) dd/mm/yy → suppose 00–69 => 2000–2069, 70–99 => 1970–1999\n",
    "    m3 = x.str.match(r\"^\\d{1,2}/\\d{1,2}/\\d{2}$\", na=False)\n",
    "    if m3.any():\n",
    "        tmp = x.loc[m3].copy()\n",
    "        # ajoute le siècle\n",
    "        yy = tmp.str.extract(r\"(\\d{2})$\")[0].astype(int)\n",
    "        century = np.where(yy >= 70, \"19\", \"20\")\n",
    "        # reconstruit en dd/mm/yyyy\n",
    "        tmp_full = tmp.str.replace(r\"/(\\d{2})$\", lambda m: f\"/{century[tmp.index.get_loc(m.start())]}{m.group(1)}\", regex=True)\n",
    "        out.loc[m3] = pd.to_datetime(tmp_full, format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "\n",
    "    # 5) Dernière passe permissive sur le reste (dayfirst=True)\n",
    "    rem = out.isna()\n",
    "    if rem.any():\n",
    "        out.loc[rem] = pd.to_datetime(x.loc[rem], errors=\"coerce\", dayfirst=True)\n",
    "\n",
    "    return out\n",
    "\n",
    "# --- applique sur ton df déjà chargé (depuis dvf_clean.parquet) ---\n",
    "before = dvf.get(\"annee\")\n",
    "dvf[\"date_mutation\"] = parse_dates_robust(dvf[\"date_mutation\"])\n",
    "dvf[\"annee\"] = dvf[\"date_mutation\"].dt.year\n",
    "\n",
    "print(\"Taux de dates invalides après parse robuste :\",\n",
    "      dvf[\"date_mutation\"].isna().mean().round(4))\n",
    "\n",
    "# Diagnostique rapide si encore élevé\n",
    "if dvf[\"date_mutation\"].isna().mean() > 0.1:\n",
    "    print(\"Exemples de valeurs non parsées :\")\n",
    "    print(dvf.loc[dvf[\"date_mutation\"].isna(), \"date_mutation\"].astype(str).value_counts().head(10))\n",
    "\n",
    "# Sauvegarde propre\n",
    "dvf.to_parquet(clean_fp, index=False)\n",
    "print(\"✅ Parquet regénéré :\", clean_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ec6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# 1) Retrouver la colonne date quel que soit son nom\n",
    "name_map = {c.lower().strip(): c for c in dvf.columns}\n",
    "date_candidates = [\"date_mutation\", \"date mutation\", \"date_mut\", \"date\"]\n",
    "date_col = next((name_map[k] for k in date_candidates if k in name_map), None)\n",
    "\n",
    "if date_col is None:\n",
    "    # tentative heuristique: première colonne contenant 'date'\n",
    "    date_col = next((c for c in dvf.columns if re.search(r\"\\bdate\\b\", c, flags=re.I)), None)\n",
    "\n",
    "if date_col is None:\n",
    "    raise KeyError(f\"Aucune colonne date trouvée dans dvf. Colonnes: {list(dvf.columns)}\")\n",
    "\n",
    "# 2) (Re)calculer l'année de façon sûre\n",
    "# Recalcule proprement l'année avec format français (jour en premier)\n",
    "dvf[\"annee\"] = pd.to_datetime(dvf[\"date_mutation\"], errors=\"coerce\", dayfirst=True).dt.year\n",
    "\n",
    "# Vérifie la validité\n",
    "nan_rate = dvf[\"annee\"].isna().mean()\n",
    "print(f\"Taux de dates invalides après correction : {nan_rate:.1%}\")\n",
    "\n",
    "# Sauvegarde propre\n",
    "dvf.to_parquet(clean_fp, index=False)\n",
    "print(\"✅ Parquet mis à jour avec dates corrigées :\", clean_fp)\n",
    "\n",
    "# 3) Optionnel: si beaucoup de NaN d'année, signale le problème de parsing\n",
    "nan_rate = dvf[\"annee\"].isna().mean()\n",
    "if nan_rate > 0.5:\n",
    "    print(f\"⚠️ Plus de 50% des dates sont invalides ({nan_rate:.0%}). Vérifie le format de '{date_col}'.\")\n",
    "\n",
    "# 4) Sauvegarder à nouveau le parquet avec 'annee' pour accélérer les prochains runs\n",
    "from pathlib import Path\n",
    "CLEAN_DIR = Path(CLEAN_DIR)\n",
    "CLEAN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "clean_fp = CLEAN_DIR / \"dvf_clean.parquet\"\n",
    "dvf.to_parquet(clean_fp, index=False)\n",
    "print(\"✅ 'annee' ajoutée et parquet mis à jour →\", clean_fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642e1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dvf.head(5))\n",
    "print(dvf[\"annee\"].value_counts().sort_index().tail(10))\n",
    "print(dvf[\"nom_commune\"].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a228035f",
   "metadata": {},
   "source": [
    "popo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntRangeSlider, FloatSlider, IntSlider, Checkbox, HBox, VBox, Output, HTML\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "CLEAN_DIR = os.path.abspath(os.path.join(\"..\", \"data\", \"clean\"))\n",
    "df = pd.read_parquet(os.path.join(CLEAN_DIR, \"dvf_clean.parquet\"))\n",
    "\n",
    "# colonnes minimales attendues\n",
    "needed = {\"date_mutation\",\"annee\",\"valeur_fonciere\",\"surface_reelle_bati\",\"prix_m2\",\"nom_commune\"}\n",
    "missing = needed - set(df.columns)\n",
    "assert not missing, f\"Colonnes manquantes: {missing}\"\n",
    "\n",
    "# filtres de base (par sécurité)\n",
    "df = df.dropna(subset=[\"surface_reelle_bati\",\"valeur_fonciere\",\"prix_m2\",\"nom_commune\"]).copy()\n",
    "df = df[(df[\"surface_reelle_bati\"] > 8) & (df[\"valeur_fonciere\"] > 1000) & (df[\"prix_m2\"].between(100, 30000))]\n",
    "\n",
    "len(df), df[\"annee\"].min(), df[\"annee\"].max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23feb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_surface = IntRangeSlider(value=(20, 80), min=10, max=200, step=1,\n",
    "                           description=\"Surface (m²)\", continuous_update=False)\n",
    "\n",
    "w_loyer = FloatSlider(value=22.0, min=5.0, max=45.0, step=0.5,\n",
    "                      readout_format=\".1f\", description=\"Loyer €/m²\", continuous_update=False)\n",
    "\n",
    "w_topn = IntSlider(value=15, min=5, max=50, step=1, description=\"Top N\", continuous_update=False)\n",
    "w_out  = Checkbox(value=True, description=\"Filtrer outliers (IQR)\")\n",
    "\n",
    "out = Output()\n",
    "display(VBox([HBox([w_surface, w_loyer]), HBox([w_topn, w_out]), out]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615ec3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr_bounds(s, k=2.0):\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    return q1 - k*iqr, q3 + k*iqr\n",
    "\n",
    "def apply_outliers(d, use_iqr=True):\n",
    "    if not use_iqr or len(d) < 50:\n",
    "        return d\n",
    "    lo, hi = iqr_bounds(d[\"prix_m2\"], k=2.0)\n",
    "    return d[d[\"prix_m2\"].between(lo, hi)]\n",
    "\n",
    "def filter_by_surface(d: pd.DataFrame, s_range):\n",
    "    smin, smax = s_range\n",
    "    return d[d[\"surface_reelle_bati\"].between(smin, smax)]\n",
    "\n",
    "def compute_yield(d: pd.DataFrame, loyer_m2: float) -> pd.DataFrame:\n",
    "    res = d.copy()\n",
    "    res[\"revenu_annuel\"] = loyer_m2 * res[\"surface_reelle_bati\"] * 12.0\n",
    "    res[\"yield_brut\"]    = res[\"revenu_annuel\"] / res[\"valeur_fonciere\"]\n",
    "    return res\n",
    "\n",
    "def render(_=None):\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        d = filter_by_surface(df, w_surface.value)\n",
    "        d = apply_outliers(d, w_out.value)\n",
    "        d = compute_yield(d, w_loyer.value)\n",
    "\n",
    "        # Classement communes par rendement médian\n",
    "        rank = (d.groupby(\"nom_commune\", dropna=False)\n",
    "                  .agg(nb=(\"prix_m2\",\"count\"),\n",
    "                       prix_m2_med=(\"prix_m2\",\"median\"),\n",
    "                       surf_med=(\"surface_reelle_bati\",\"median\"),\n",
    "                       yield_brut_med=(\"yield_brut\",\"median\"),\n",
    "                       yield_p90=(\"yield_brut\", lambda s: s.quantile(0.90)))\n",
    "                  .sort_values(\"yield_brut_med\", ascending=False)\n",
    "                  .head(w_topn.value)\n",
    "                  .reset_index())\n",
    "\n",
    "        display(HTML(\"<h4>Top communes (rendement brut médian)</h4>\"))\n",
    "        display(rank)\n",
    "\n",
    "        # Histogramme (cap à 25% pour lisibilité)\n",
    "        plt.figure()\n",
    "        d[\"yield_brut\"].dropna().clip(upper=0.25).plot(kind=\"hist\", bins=40)\n",
    "        plt.xlabel(\"Rendement brut\")\n",
    "        plt.ylabel(\"Nombre de ventes\")\n",
    "        plt.title(\"Distribution des rendements (Surface + Loyer €/m²)\")\n",
    "        plt.show()\n",
    "\n",
    "w_surface.observe(render, \"value\")\n",
    "w_loyer.observe(render, \"value\")\n",
    "w_topn.observe(render, \"value\")\n",
    "w_out.observe(render, \"value\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntRangeSlider, FloatSlider, Checkbox, IntSlider, Output, VBox, HBox, HTML\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# --- Widgets ---\n",
    "w_surface = IntRangeSlider(\n",
    "    value=[15, 60],\n",
    "    min=10, max=200, step=5,\n",
    "    description='Surface (m²)',\n",
    "    continuous_update=False,\n",
    "    layout={'width': '400px'}\n",
    ")\n",
    "\n",
    "w_loyer = FloatSlider(\n",
    "    value=25.0, min=10, max=60, step=0.5,\n",
    "    description='Loyer €/m²/mois',\n",
    "    continuous_update=False,\n",
    "    layout={'width': '400px'}\n",
    ")\n",
    "\n",
    "w_topn = IntSlider(\n",
    "    value=10, min=5, max=50, step=5,\n",
    "    description='Top N',\n",
    "    continuous_update=False,\n",
    "    layout={'width': '400px'}\n",
    ")\n",
    "\n",
    "w_out = Checkbox(\n",
    "    value=True,\n",
    "    description='Exclure outliers (IQR)',\n",
    ")\n",
    "\n",
    "out = Output()\n",
    "\n",
    "# --- Assemblage des contrôles ---\n",
    "controls = VBox([\n",
    "    HTML(\"<h3>Paramètres d’analyse</h3>\"),\n",
    "    HBox([w_surface, w_loyer]),\n",
    "    HBox([w_topn, w_out])\n",
    "])\n",
    "\n",
    "display(controls, out)\n",
    "\n",
    "render()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac12f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Dashboard Surface & Loyer (Widgets 5 et 6) ====\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as W\n",
    "from IPython.display import display, clear_output, HTML\n",
    "\n",
    "# --------- Helpers métriques ---------\n",
    "def iqr_bounds(s, k=2.0):\n",
    "    q1, q3 = s.quantile(0.25), s.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    return q1 - k*iqr, q3 + k*iqr\n",
    "\n",
    "def apply_outliers(d, use_iqr=True):\n",
    "    if not use_iqr or len(d) < 50:\n",
    "        return d\n",
    "    lo, hi = iqr_bounds(d[\"prix_m2\"], k=2.0)\n",
    "    return d[d[\"prix_m2\"].between(lo, hi)]\n",
    "\n",
    "def filter_by_surface(d: pd.DataFrame, s_range):\n",
    "    smin, smax = s_range\n",
    "    return d[d[\"surface_reelle_bati\"].between(smin, smax)]\n",
    "\n",
    "def compute_yield(d: pd.DataFrame, loyer_m2: float) -> pd.DataFrame:\n",
    "    res = d.copy()\n",
    "    res[\"revenu_annuel\"] = loyer_m2 * res[\"surface_reelle_bati\"] * 12.0\n",
    "    res[\"yield_brut\"]    = res[\"revenu_annuel\"] / res[\"valeur_fonciere\"]\n",
    "    return res\n",
    "\n",
    "def kpis_html(d):\n",
    "    nb = f\"{len(d):,}\".replace(\",\", \" \")\n",
    "    p50 = (d[\"prix_m2\"].median() if len(d) else np.nan)\n",
    "    y50 = (d[\"yield_brut\"].median()*100 if len(d) else np.nan)\n",
    "    return HTML(f\"\"\"\n",
    "    <div style='display:flex;gap:28px;margin:8px 0 12px 0;font-family:system-ui,Segoe UI,Roboto,Arial'>\n",
    "      <div><div style=\"opacity:.7\">Nb ventes</div><div style=\"font-size:18px\">{nb}</div></div>\n",
    "      <div><div style=\"opacity:.7\">Prix/m² médian</div><div style=\"font-size:18px\">{p50:.0f} €</div></div>\n",
    "      <div><div style=\"opacity:.7\">Rendement médian</div><div style=\"font-size:18px\">{y50:.2f} %</div></div>\n",
    "    </div>\"\"\")\n",
    "\n",
    "# --------- Widgets (5 & 6 + options utiles) ---------\n",
    "w_surface = W.IntRangeSlider(value=[20, 80], min=10, max=200, step=1,\n",
    "                             description='Surface (m²)', continuous_update=False, layout=W.Layout(width='360px'))\n",
    "w_loyer   = W.FloatSlider(value=22.0, min=5.0, max=45.0, step=0.5,\n",
    "                          readout_format=\".1f\", description='Loyer €/m²', continuous_update=False, layout=W.Layout(width='360px'))\n",
    "w_topn    = W.IntSlider(value=15, min=5, max=50, step=1, description='Top N', continuous_update=False, layout=W.Layout(width='360px'))\n",
    "w_out     = W.Checkbox(value=True, description='Exclure outliers (IQR)')\n",
    "\n",
    "# (option) filtre par type_local si présent\n",
    "type_opts = sorted(df[\"type_local\"].dropna().unique()) if \"type_local\" in df.columns else []\n",
    "w_type    = W.SelectMultiple(options=type_opts, value=tuple(type_opts) if type_opts else (),\n",
    "                             description='Type', rows=min(6, len(type_opts))) if type_opts else None\n",
    "\n",
    "# Actions\n",
    "btn_reset = W.Button(description=\"Réinitialiser filtres\")\n",
    "btn_export = W.Button(description=\"Exporter le classement (CSV)\")\n",
    "\n",
    "# Zones d’affichage\n",
    "out_table = W.Output()\n",
    "out_plot1 = W.Output()\n",
    "out_plot2 = W.Output()\n",
    "out_kpi   = W.Output()\n",
    "\n",
    "# --------- Rendu principal ---------\n",
    "def render(_=None):\n",
    "    with out_table:\n",
    "        clear_output(wait=True)\n",
    "    with out_plot1:\n",
    "        clear_output(wait=True)\n",
    "    with out_plot2:\n",
    "        clear_output(wait=True)\n",
    "    with out_kpi:\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    # 1) filtrage surface + (option) type\n",
    "    d = filter_by_surface(df, w_surface.value)\n",
    "    if w_type and len(w_type.value) > 0:\n",
    "        d = d[d[\"type_local\"].isin(w_type.value)]\n",
    "\n",
    "    # 2) outliers IQR\n",
    "    d = apply_outliers(d, w_out.value)\n",
    "\n",
    "    # 3) rendement\n",
    "    d = compute_yield(d, w_loyer.value)\n",
    "\n",
    "    # 4) KPIs\n",
    "    with out_kpi:\n",
    "        display(kpis_html(d))\n",
    "\n",
    "    # 5) Classement communes\n",
    "    rank = (d.groupby(\"nom_commune\", dropna=False)\n",
    "              .agg(nb=(\"prix_m2\",\"count\"),\n",
    "                   prix_m2_med=(\"prix_m2\",\"median\"),\n",
    "                   surf_med=(\"surface_reelle_bati\",\"median\"),\n",
    "                   yield_brut_med=(\"yield_brut\",\"median\"),\n",
    "                   yield_p90=(\"yield_brut\", lambda s: s.quantile(0.90)))\n",
    "              .sort_values(\"yield_brut_med\", ascending=False)\n",
    "              .head(w_topn.value)\n",
    "              .reset_index())\n",
    "\n",
    "    # 6) Tableau\n",
    "    with out_table:\n",
    "        display(HTML(\"<h4>Top communes (rendement brut médian)</h4>\"))\n",
    "        display(rank)\n",
    "\n",
    "    # 7) Graphes (Matplotlib uniquement)\n",
    "    # 7a) Histogramme des rendements\n",
    "    with out_plot1:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        d[\"yield_brut\"].dropna().clip(upper=0.25).plot(kind=\"hist\", bins=40)\n",
    "        plt.xlabel(\"Rendement brut\")\n",
    "        plt.ylabel(\"Nombre de ventes\")\n",
    "        plt.title(\"Distribution des rendements (Surface & Loyer)\")\n",
    "        plt.show()\n",
    "\n",
    "    # 7b) Barplot Top N par rendement médian\n",
    "    with out_plot2:\n",
    "        plt.figure(figsize=(7.5,4.5))\n",
    "        x = rank[\"nom_commune\"].astype(str)\n",
    "        y = (rank[\"yield_brut_med\"]*100).round(2)\n",
    "        plt.bar(x, y)\n",
    "        plt.xticks(rotation=60, ha=\"right\")\n",
    "        plt.ylabel(\"Rendement médian (%)\")\n",
    "        plt.title(\"Top communes par rendement médian\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    # 8) Stocker le dernier ranking pour export\n",
    "    btn_export._last_rank = rank.copy()\n",
    "\n",
    "# --------- Actions boutons ---------\n",
    "def on_reset(_):\n",
    "    w_surface.value = (20, 80)\n",
    "    w_loyer.value   = 22.0\n",
    "    w_topn.value    = 15\n",
    "    w_out.value     = True\n",
    "    if w_type:\n",
    "        w_type.value = tuple(type_opts)\n",
    "    render()\n",
    "\n",
    "def on_export(_):\n",
    "    rank = getattr(btn_export, \"_last_rank\", None)\n",
    "    if rank is None or rank.empty:\n",
    "        with out_table:\n",
    "            display(HTML(\"<i>Aucun classement à exporter.</i>\"))\n",
    "        return\n",
    "    # Export dans data/clean\n",
    "    out_csv = os.path.join(CLEAN_DIR, \"classement_communes_surface_loyer.csv\")\n",
    "    rank.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "    with out_table:\n",
    "        display(HTML(f\"<b>Exporté :</b> {out_csv}\"))\n",
    "\n",
    "btn_reset.on_click(on_reset)\n",
    "btn_export.on_click(on_export)\n",
    "\n",
    "# --------- Layout / Interface ---------\n",
    "controls_left = [\n",
    "    HTML(\"<h3 style='margin:0 0 6px 0'>Filtres</h3>\"),\n",
    "    w_surface, w_loyer, w_topn, w_out\n",
    "]\n",
    "if w_type:\n",
    "    controls_left.insert(2, w_type)\n",
    "\n",
    "box_left = W.VBox(controls_left + [W.HBox([btn_reset, btn_export])],\n",
    "                  layout=W.Layout(width=\"400px\"))\n",
    "\n",
    "box_right = W.VBox([\n",
    "    out_kpi,\n",
    "    out_table,\n",
    "    W.HBox([out_plot1, out_plot2])\n",
    "])\n",
    "\n",
    "ui = W.HBox([box_left, box_right], layout=W.Layout(align_items=\"flex-start\"))\n",
    "display(ui)\n",
    "\n",
    "# Observers\n",
    "w_surface.observe(render, \"value\")\n",
    "w_loyer.observe(render, \"value\")\n",
    "w_topn.observe(render, \"value\")\n",
    "w_out.observe(render, \"value\")\n",
    "if w_type:\n",
    "    w_type.observe(render, \"value\")\n",
    "\n",
    "# Premier rendu\n",
    "render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d860dcbe",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Import automatique de `02_widget5_6.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcbfca7",
   "metadata": {},
   "source": [
    "## Imports, chargement robuste et normalisation des colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b06bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Imports\n",
    "import os, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import IntRangeSlider, FloatSlider, HBox, Output, HTML\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "CLEAN_DIR = os.path.abspath(os.path.join(\"..\", \"data\", \"clean\"))\n",
    "RAW_DIR   = os.path.abspath(os.path.join(\"..\", \"data\", \"raw\"))\n",
    "clean_fp  = os.path.join(CLEAN_DIR, \"dvf_clean.parquet\")\n",
    "raw_txt   = os.path.join(RAW_DIR, \"DVF_2025_S1.txt\")  # ton fichier texte DVF renommé\n",
    "\n",
    "def _to_num(s):\n",
    "    return pd.to_numeric(s.astype(str).str.replace(\",\", \".\", regex=False), errors=\"coerce\")\n",
    "\n",
    "def load_dvf():\n",
    "    # 1) Essaye d'abord le parquet propre\n",
    "    if os.path.exists(clean_fp):\n",
    "        df = pd.read_parquet(clean_fp)\n",
    "    else:\n",
    "        # 2) Sinon, fallback rapide sur le .txt DVF (séparateur |)\n",
    "        usecols = [\n",
    "            \"Date mutation\",\"Nature mutation\",\"Valeur fonciere\",\n",
    "            \"Code postal\",\"Commune\",\"Code departement\",\"Code commune\",\n",
    "            \"Type local\",\"Surface reelle bati\",\"Nombre pieces principales\"\n",
    "        ]\n",
    "        df = pd.read_csv(raw_txt, sep=\"|\", dtype=str, low_memory=False)\n",
    "        df = df[[c for c in usecols if c in df.columns]].copy()\n",
    "\n",
    "        # Typage & filtres minimum\n",
    "        df[\"Valeur fonciere\"] = _to_num(df[\"Valeur fonciere\"])\n",
    "        df[\"Surface reelle bati\"] = _to_num(df[\"Surface reelle bati\"])\n",
    "        df[\"Date mutation\"] = pd.to_datetime(df[\"Date mutation\"], errors=\"coerce\")\n",
    "\n",
    "        # Ventes + Île-de-France\n",
    "        df = df[df[\"Nature mutation\"].fillna(\"\").str.contains(\"Vente\", case=False, na=False)]\n",
    "        idf_prefix = (\"75\",\"77\",\"78\",\"91\",\"92\",\"93\",\"94\",\"95\")\n",
    "        df = df[df[\"Code departement\"].astype(str).str.startswith(idf_prefix)]\n",
    "\n",
    "        # prix/m²\n",
    "        df[\"prix_m2\"] = df[\"Valeur fonciere\"] / df[\"Surface reelle bati\"]\n",
    "        df = df[(df[\"Surface reelle bati\"] > 8) & (df[\"prix_m2\"].between(100, 30000))]\n",
    "\n",
    "        # Sauvegarde clean (optionnel)\n",
    "        os.makedirs(CLEAN_DIR, exist_ok=True)\n",
    "        df.rename(columns={\n",
    "            \"Date mutation\":\"date_mutation\",\n",
    "            \"Valeur fonciere\":\"valeur_fonciere\",\n",
    "            \"Surface reelle bati\":\"surface_reelle_bati\",\n",
    "            \"Commune\":\"nom_commune\",\n",
    "            \"Code postal\":\"code_postal\",\n",
    "            \"Type local\":\"type_local\"\n",
    "        }, inplace=True)\n",
    "        df.to_parquet(clean_fp, index=False)\n",
    "\n",
    "    # Normalisation des noms attendus par le dashboard\n",
    "    rename_map = {\n",
    "        \"Date mutation\":\"date_mutation\",\n",
    "        \"Valeur fonciere\":\"valeur_fonciere\",\n",
    "        \"Surface reelle bati\":\"surface_reelle_bati\",\n",
    "        \"Commune\":\"nom_commune\",\n",
    "        \"Code postal\":\"code_postal\",\n",
    "        \"Type local\":\"type_local\"\n",
    "    }\n",
    "    df = df.rename(columns=rename_map)\n",
    "\n",
    "    # Colonnes minimales\n",
    "    needed = [\"date_mutation\",\"valeur_fonciere\",\"surface_reelle_bati\",\"prix_m2\",\"nom_commune\"]\n",
    "    # Si prix_m2 absent (cas parquet externe), on le recalcule\n",
    "    if \"prix_m2\" not in df.columns and all(c in df.columns for c in [\"valeur_fonciere\",\"surface_reelle_bati\"]):\n",
    "        df[\"prix_m2\"] = df[\"valeur_fonciere\"] / df[\"surface_reelle_bati\"]\n",
    "\n",
    "    # Nettoyage final minimal\n",
    "    df = df.dropna(subset=[\"surface_reelle_bati\",\"valeur_fonciere\",\"prix_m2\",\"nom_commune\"]).copy()\n",
    "    df = df[(df[\"surface_reelle_bati\"] > 8) & (df[\"valeur_fonciere\"] > 1000) & (df[\"prix_m2\"].between(100, 30000))]\n",
    "    df[\"annee\"] = pd.to_datetime(df[\"date_mutation\"], errors=\"coerce\").dt.year\n",
    "    return df[needed + [\"annee\"]]\n",
    "\n",
    "df = load_dvf()\n",
    "len(df), df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a2d2e7",
   "metadata": {},
   "source": [
    "## Widgets 5 (surface) & 6 (loyer €/m²)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30a8698",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_surface = IntRangeSlider(\n",
    "    value=(20, 80),\n",
    "    min=10, max=200, step=1,\n",
    "    description=\"Surface (m²)\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "# Valeur par défaut réaliste pour IDF (tu peux ajuster)\n",
    "w_loyer = FloatSlider(\n",
    "    value=22.0, min=5.0, max=45.0, step=0.5,\n",
    "    readout_format=\".1f\",\n",
    "    description=\"Loyer €/m²\",\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "out = Output()\n",
    "display(HBox([w_surface, w_loyer]), out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95403e6e",
   "metadata": {},
   "source": [
    "## Fonctions + rendu (tableau Top communes + histogramme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89979c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_surface(d: pd.DataFrame, s_range):\n",
    "    smin, smax = s_range\n",
    "    return d[d[\"surface_reelle_bati\"].between(smin, smax)]\n",
    "\n",
    "def compute_yield(d: pd.DataFrame, loyer_m2: float) -> pd.DataFrame:\n",
    "    res = d.copy()\n",
    "    # Revenu annuel estimé (brut)\n",
    "    res[\"revenu_annuel\"] = loyer_m2 * res[\"surface_reelle_bati\"] * 12.0\n",
    "    res[\"yield_brut\"] = res[\"revenu_annuel\"] / res[\"valeur_fonciere\"]\n",
    "    return res\n",
    "\n",
    "def render(_=None):\n",
    "    with out:\n",
    "        clear_output(wait=True)\n",
    "        d = filter_by_surface(df, w_surface.value)\n",
    "        d = compute_yield(d, w_loyer.value)\n",
    "\n",
    "        # Classement communes par rendement médian\n",
    "        g = (d.groupby(\"nom_commune\", dropna=False)\n",
    "               .agg(nb=(\"prix_m2\",\"count\"),\n",
    "                    prix_m2_med=(\"prix_m2\",\"median\"),\n",
    "                    surf_med=(\"surface_reelle_bati\",\"median\"),\n",
    "                    yield_brut_med=(\"yield_brut\",\"median\"))\n",
    "               .sort_values(\"yield_brut_med\", ascending=False)\n",
    "               .head(15)\n",
    "               .reset_index())\n",
    "\n",
    "        display(HTML(\"<h4>Top 15 communes (rendement brut médian)</h4>\"))\n",
    "        display(g)\n",
    "\n",
    "        # Histogramme des rendements (capé à 25% pour lisibilité)\n",
    "        plt.figure()\n",
    "        d[\"yield_brut\"].dropna().clip(upper=0.25).plot(kind=\"hist\", bins=40)\n",
    "        plt.xlabel(\"Rendement brut\")\n",
    "        plt.ylabel(\"Nombre de ventes\")\n",
    "        plt.title(\"Distribution des rendements (Surface + Loyer €/m²)\")\n",
    "        plt.show()\n",
    "\n",
    "w_surface.observe(render, \"value\")\n",
    "w_loyer.observe(render, \"value\")\n",
    "render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f725f2f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Import automatique de `03_analyse_loyers_IDF.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd1dcfe",
   "metadata": {},
   "source": [
    "# 03 — Analyse des loyers (Île-de-France)\n",
    "\n",
    "Notebook interactif pour explorer le fichier de loyers `pred-app12-mef-dhup_2024.csv`.\n",
    "**Objectifs** : charger, nettoyer, filtrer IDF, visualiser distribution et proposer un widget pour lister\n",
    "communes dont le loyer prédit est sous la moyenne (ou selon un seuil choisi).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c54634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, warnings\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, widgets, HBox, VBox, fixed\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Chemins — modifiables\n",
    "default_paths = [\n",
    "    os.path.join(\"data\",\"raw\",\"pred-app12-mef-dhup_2024.csv\"),\n",
    "    os.path.join(\"..\",\"data\",\"raw\",\"pred-app12-mef-dhup_2024.csv\"),\n",
    "    r\"C:/Users/Victor/DataScience/Projet-Data-science-Investissement-immobilier/pred-app12-mef-dhup_2024.csv\"\n",
    "]\n",
    "\n",
    "csv_path = None\n",
    "for p in default_paths:\n",
    "    if os.path.exists(p):\n",
    "        csv_path = p; break\n",
    "\n",
    "print('Chemin utilisé pour le fichier loyers :', csv_path or \"Aucun fichier trouvé automatiquement — modifiez csv_path manuellement\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d90ff5",
   "metadata": {},
   "source": [
    "## 1) Chargement et nettoyage initial\n",
    "- Lecture robuste (latin-1 ou utf-8)\n",
    "- Conversion du code INSEE en str\n",
    "- Extraction numérique du champ `loypredm2` et création de `loy_num`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3242ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lecture flexible\n",
    "if csv_path is None:\n",
    "    raise FileNotFoundError(\"Aucun fichier de loyers trouvé automatiquement. Déposez pred-app12-mef-dhup_2024.csv dans data/raw/ ou modifiez csv_path.\")\n",
    "\n",
    "# Essayer plusieurs encodages/sep si nécessaire\n",
    "try:\n",
    "    df_raw = pd.read_csv(csv_path, sep=None, engine=\"python\", dtype=str, encoding=\"utf-8\")\n",
    "except Exception as e:\n",
    "    df_raw = pd.read_csv(csv_path, sep=None, engine=\"python\", dtype=str, encoding=\"latin-1\")\n",
    "\n",
    "print(\"Taille initiale:\", df_raw.shape)\n",
    "display(df_raw.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb82222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standardisation colonnes (vérifie noms)\n",
    "print(\"Colonnes disponibles:\", list(df_raw.columns))\n",
    "\n",
    "# On s'assure que la colonne INSEE_C existe\n",
    "possible_insee = [c for c in df_raw.columns if c.lower().startswith(\"insee\") or c.lower().startswith(\"commune\")]\n",
    "print(\"Colonnes candidates INSEE/commune:\", possible_insee)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd1fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nettoyage / extraction numérique loypredm2 -> loy_num\n",
    "col_loy = None\n",
    "for c in df_raw.columns:\n",
    "    if 'loy' in c.lower() and 'm2' in c.lower():\n",
    "        col_loy = c; break\n",
    "if col_loy is None:\n",
    "    # heuristique: trouver colonnes contenant 'loypred' ou 'loy'\n",
    "    for c in df_raw.columns:\n",
    "        if 'loypred' in c.lower() or 'loy' in c.lower():\n",
    "            col_loy = c; break\n",
    "\n",
    "if col_loy is None:\n",
    "    raise ValueError(\"Impossible de détecter une colonne de loyer. Vérifie le fichier source.\")\n",
    "\n",
    "print('Colonne loyer détectée :', col_loy)\n",
    "\n",
    "df = df_raw.copy()\n",
    "# Nettoyage du champ loyer : remplacer virgule, extraire float\n",
    "df['loy_raw'] = df[col_loy].astype(str)\n",
    "df['loy_num'] = df['loy_raw'].str.replace(',', '.', regex=False).str.extract(r'([0-9]+\\.?[0-9]*)')[0].astype(float)\n",
    "# colonne INSEE\n",
    "insee_candidates = [c for c in df.columns if c.lower().startswith('insee')]\n",
    "if len(insee_candidates)>0:\n",
    "    df['INSEE_C'] = df[insee_candidates[0]].astype(str).str.strip()\n",
    "else:\n",
    "    # tenter 'CODGEO' ou 'COM' ou 'INSEE_C'\n",
    "    for c in ['CODGEO','COM','code_commune','code_INSEE','INSEE_C']:\n",
    "        if c in df.columns:\n",
    "            df['INSEE_C'] = df[c].astype(str).str.strip(); break\n",
    "\n",
    "print('Total lignes après extraction loy_num:', len(df))\n",
    "df[['INSEE_C','loy_raw','loy_num']].head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75241670",
   "metadata": {},
   "source": [
    "## 2) Filtrer Île-de-France\n",
    "On considère comme préfixes IDF : 75,77,78,91,92,93,94,95 (code départemental en début du code INSEE / COM).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b412f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtrage IDF\n",
    "idf_prefix = ('75','77','78','91','92','93','94','95')\n",
    "\n",
    "if 'INSEE_C' not in df.columns:\n",
    "    raise ValueError(\"Colonne INSEE_C manquante. Vérifie le fichier source ou adapte le notebook.\")\n",
    "\n",
    "df['INSEE_C'] = df['INSEE_C'].astype(str).str.zfill(5)\n",
    "df_idf = df[df['INSEE_C'].str.startswith(idf_prefix, na=False)].copy()\n",
    "print(f\"Lignes totales: {len(df)} | Lignes IDF: {len(df_idf)}\")\n",
    "\n",
    "# moyenne IDF\n",
    "mean_val = df_idf['loy_num'].mean(skipna=True)\n",
    "print(f\"Moyenne loypredm2 IDF: {mean_val:.2f} €/m²\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bc04fe",
   "metadata": {},
   "source": [
    "## 3) Visualisations (Matplotlib uniquement)\n",
    "- Distribution des loyers (histogramme)\n",
    "- Boxplot par département\n",
    "- Carte non incluse dans ce notebook (sera faite dans notebook gares si besoin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e631b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distribution loyers\n",
    "plt.figure()\n",
    "plt.hist(df_idf['loy_num'].dropna(), bins=50)\n",
    "plt.title('Distribution des loyers prédits (€/m²) — IDF')\n",
    "plt.xlabel('€/m²'); plt.ylabel('Nombre de lignes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Moyenne par département (par code INSEE -> département = 2 premiers digits)\n",
    "df_idf['dept'] = df_idf['INSEE_C'].str[:2]\n",
    "dept_stats = df_idf.groupby('dept')['loy_num'].agg(['count','mean','median']).reset_index().sort_values('mean', ascending=False)\n",
    "plt.figure()\n",
    "plt.bar(dept_stats['dept'], dept_stats['mean'])\n",
    "plt.title('Loyer moyen (€/m²) par département — IDF')\n",
    "plt.xlabel('Département'); plt.ylabel('Loyer moyen €/m²')\n",
    "plt.show()\n",
    "\n",
    "display(dept_stats.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d4e961",
   "metadata": {},
   "source": [
    "## 4) Widgets interactifs\n",
    "- Sélecteur de département\n",
    "- Slider de seuil (<= moyenne par défaut)\n",
    "- Bouton pour exporter la shortlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cda4c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Widgets\n",
    "dept_options = ['(Tous)'] + dept_stats['dept'].tolist()\n",
    "dept_dd = widgets.Dropdown(options=dept_options, description='Dépt:')\n",
    "seuil = widgets.FloatSlider(value=mean_val, min=0, max=max(df_idf['loy_num'].dropna().max(), mean_val*2), step=0.5, description='Seuil €/m²:')\n",
    "topn = widgets.IntSlider(value=20, min=5, max=200, step=5, description='Top N:')\n",
    "\n",
    "def shortlist(dept, seuil_val, topn_val):\n",
    "    d = df_idf.copy()\n",
    "    if dept != '(Tous)':\n",
    "        d = d[d['INSEE_C'].str.startswith(dept)]\n",
    "    d = d[d['loy_num'] <= seuil_val].copy()\n",
    "    # agrégation commune si colonne existante\n",
    "    comm_col = None\n",
    "    for c in ['commune', 'nom_commune', 'NOM_COM', 'LIBGEO', 'LIBELLE_COMMUNE']:\n",
    "        if c in d.columns:\n",
    "            comm_col = c; break\n",
    "    if comm_col is None:\n",
    "        # regroupe sur INSEE\n",
    "        grp = d.groupby('INSEE_C').agg(nb=('loy_num','count'), loy_med=('loy_num','median')).reset_index().sort_values('loy_med')\n",
    "    else:\n",
    "        grp = d.groupby(comm_col).agg(nb=('loy_num','count'), loy_med=('loy_num','median')).reset_index().sort_values('loy_med')\n",
    "    display(grp.head(topn_val))\n",
    "    return grp.head(topn_val)\n",
    "\n",
    "out = widgets.interactive_output(shortlist, {'dept':dept_dd, 'seuil_val':seuil, 'topn_val':topn})\n",
    "display(HBox([dept_dd, seuil, topn]))\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792d0be2",
   "metadata": {},
   "source": [
    "## 5) Exporter les résultats filtrés\n",
    "Tu peux sauvegarder la shortlist (CSV) sur disque.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fff09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction d'export\n",
    "def export_shortlist(df_short, fname='shortlist_loyers_idf.csv'):\n",
    "    outp = os.path.join('data','clean', fname)\n",
    "    os.makedirs(os.path.dirname(outp), exist_ok=True)\n",
    "    df_short.to_csv(outp, index=False, encoding='utf-8-sig')\n",
    "    print('Exporté →', outp)\n",
    "\n",
    "# Exemple d'usage :\n",
    "# grp = shortlist('(Tous)', mean_val, 20)\n",
    "# export_shortlist(grp)\n",
    "print('Cellule prête pour export.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665b3aea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Import automatique de `04_accessibilite_gare_IDF.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd850aec",
   "metadata": {},
   "source": [
    "# 04 — Analyse Accessibilité des gares\n",
    "\n",
    "Notebook pour explorer `accessibilite-en-gare.csv` et produire :\n",
    "- filtrage par niveau d'accessibilité\n",
    "- stats par département\n",
    "- top gares/communes accessibles\n",
    "- widgets interactifs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1f4023",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, warnings\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, widgets, HBox, VBox\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# chemins par défaut (modifiables)\n",
    "default_paths = [\n",
    "    os.path.join(\"data\",\"raw\",\"accessibilite-en-gare.csv\"),\n",
    "    os.path.join(\"..\",\"data\",\"raw\",\"accessibilite-en-gare.csv\"),\n",
    "    r\"C:/Users/Victor/DataScience/Projet-Data-science-Investissement-immobilier/accessibilite-en-gare.csv\"\n",
    "]\n",
    "\n",
    "csv_path = None\n",
    "for p in default_paths:\n",
    "    if os.path.exists(p):\n",
    "        csv_path = p; break\n",
    "\n",
    "print('Chemin utilisé pour accessibilite:', csv_path or \"Aucun fichier trouvé automatiquement — modifiez csv_path si besoin\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b6c933",
   "metadata": {},
   "source": [
    "## Chargement et typage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744a784c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if csv_path is None:\n",
    "    raise FileNotFoundError(\"Aucun fichier accessibilite-en-gare.csv trouvé. Déposez le fichier dans data/raw/\")\n",
    "\n",
    "df_raw = pd.read_csv(csv_path, sep=';', engine='python', dtype=str)\n",
    "print(\"Taille initiale:\", df_raw.shape)\n",
    "display(df_raw.head(3))\n",
    "print(\"Colonnes:\", list(df_raw.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57152dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# conversion accessibility_level_id\n",
    "col_acc = None\n",
    "for c in df_raw.columns:\n",
    "    if 'accessibility_level' in c.lower() or 'accessibilit' in c.lower():\n",
    "        col_acc = c; break\n",
    "if col_acc is None:\n",
    "    raise ValueError(\"Impossible de trouver la colonne d'accessibilité dans le fichier.\")\n",
    "\n",
    "df_raw[col_acc] = pd.to_numeric(df_raw[col_acc], errors='coerce')\n",
    "print('Colonne accessibilité détectée :', col_acc)\n",
    "df = df_raw.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a44c5c",
   "metadata": {},
   "source": [
    "## Filtrage — niveau minimal d'accessibilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177d0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# distribution\n",
    "print(\"Distribution niveaux accessibilité:\")\n",
    "display(df[col_acc].value_counts().sort_index())\n",
    "\n",
    "# Par défaut, on garde niveaux >=3\n",
    "df_filtered = df[df[col_acc] >= 3].copy()\n",
    "print(\"Gares avec niveau >=3 :\", len(df_filtered))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95237ae",
   "metadata": {},
   "source": [
    "## Visualisations (Matplotlib)\n",
    "- Histogramme des niveaux\n",
    "- Top communes par nombre de gares accessibles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eed460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# histogramme des niveaux (toutes gares)\n",
    "plt.figure()\n",
    "plt.hist(df[col_acc].dropna().astype(int), bins=range(int(df[col_acc].min()), int(df[col_acc].max())+2))\n",
    "plt.title('Histogramme des niveaux d accessibilité')\n",
    "plt.xlabel('Niveau accessibilité'); plt.ylabel('Nombre de gares')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6102bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Top communes avec le plus de gares accessibles (colonne commune possible)\n",
    "comm_col = None\n",
    "for c in ['stop_name','commune','nom_commune','town','locality']:\n",
    "    if c in df.columns:\n",
    "        comm_col = c; break\n",
    "if comm_col is None:\n",
    "    # fallback sur stop_point_id ou autre\n",
    "    comm_col = 'stop_point_id'\n",
    "\n",
    "top_comm = df_filtered.groupby(comm_col).size().reset_index(name='count').sort_values('count', ascending=False).head(20)\n",
    "display(top_comm)\n",
    "plt.figure()\n",
    "plt.bar(top_comm[comm_col].astype(str), top_comm['count'])\n",
    "plt.title('Top gares / commune (niveau >=3)')\n",
    "plt.xlabel('Commune/Gare'); plt.ylabel('Nombre de gares')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197a43f5",
   "metadata": {},
   "source": [
    "## Widgets interactifs\n",
    "- Slider niveau minimal (1–5)\n",
    "- Filtre texte sur nom de gare / commune\n",
    "- Export CSV des gares filtrées\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "level_slider = widgets.IntSlider(value=3, min=int(df[col_acc].min()), max=int(df[col_acc].max()), step=1, description='Niveau >=')\n",
    "text_filter = widgets.Text(value='', description='Filtre nom:')\n",
    "topn = widgets.IntSlider(value=20, min=5, max=200, step=5, description='Top N:')\n",
    "\n",
    "def explore(level_min, filt_text, topn_val):\n",
    "    d = df.copy()\n",
    "    d = d[d[col_acc] >= level_min]\n",
    "    if filt_text.strip():\n",
    "        mask = d.apply(lambda row: filt_text.lower() in ' '.join([str(row.get(c,'')) for c in d.columns if isinstance(row.get(c,''), str)]).lower(), axis=1)\n",
    "        d = d[mask]\n",
    "    # agrégation par commune/gare\n",
    "    grp = d.groupby(comm_col).size().reset_index(name='count').sort_values('count', ascending=False)\n",
    "    display(grp.head(topn_val))\n",
    "    print(f\"Total gares correspondant: {len(d)}\")\n",
    "    return d, grp\n",
    "\n",
    "out = widgets.interactive_output(explore, {'level_min': level_slider, 'filt_text': text_filter, 'topn_val': topn})\n",
    "display(HBox([level_slider, text_filter, topn]))\n",
    "display(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e32979d",
   "metadata": {},
   "source": [
    "## Export des gares filtrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf96c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def export_gare(df_out, fname='gares_accessibles_filtered.csv'):\n",
    "    outp = os.path.join('data','clean', fname)\n",
    "    os.makedirs(os.path.dirname(outp), exist_ok=True)\n",
    "    df_out.to_csv(outp, index=False, encoding='utf-8-sig')\n",
    "    print('Exporté →', outp)\n",
    "\n",
    "# Exemple:\n",
    "# d, grp = explore(3, '', 20)\n",
    "# export_gare(d)\n",
    "print('Cellule prête pour export.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
